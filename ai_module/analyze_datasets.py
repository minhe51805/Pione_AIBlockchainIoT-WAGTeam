"""
Script ph√¢n t√≠ch datasets cho AI Module
- Ki·ªÉm tra c·∫•u tr√∫c, ch·∫•t l∆∞·ª£ng, missing values
- So s√°nh v·ªõi 11 th√¥ng s·ªë c·ªßa h·ªá th·ªëng
- ƒê·ªÅ xu·∫•t strategy merge/augment
"""

import pandas as pd
import numpy as np
import os

# ============================================================
# DANH S√ÅCH 11 TH√îNG S·ªê C·ª¶A H·ªÜ TH·ªêNG
# ============================================================
REQUIRED_PARAMS = {
    # Soil Indicators (8)
    'soil_temperature': '¬∞C',
    'soil_moisture': '%',
    'conductivity': '¬µS/cm',
    'ph': '',
    'nitrogen': 'mg/kg',
    'phosphorus': 'mg/kg',
    'potassium': 'mg/kg',
    'salt': 'mg/L',
    # Air/Weather Indicators (3)
    'air_temperature': '¬∞C',
    'air_humidity': '%',
    'is_raining': 'boolean'
}

print("=" * 80)
print("üîç PH√ÇN T√çCH DATASETS CHO AI MODULE - 11 TH√îNG S·ªê")
print("=" * 80)

# ============================================================
# 1. KAGGLE - CROP RECOMMENDATION DATASET
# ============================================================
print("\n" + "=" * 80)
print("üìä DATASET 1: Kaggle Crop Recommendation")
print("=" * 80)

crop_file = "../dataset/Crop_recommendation.csv"

if os.path.exists(crop_file):
    df_crop = pd.read_csv(crop_file)
    
    print(f"\n‚úÖ File loaded: {crop_file}")
    print(f"üìè Shape: {df_crop.shape[0]:,} rows √ó {df_crop.shape[1]} columns")
    
    print("\nüìã Columns:")
    for i, col in enumerate(df_crop.columns, 1):
        dtype = df_crop[col].dtype
        nulls = df_crop[col].isnull().sum()
        uniques = df_crop[col].nunique()
        print(f"  {i}. {col.ljust(15)} | Type: {str(dtype).ljust(10)} | Nulls: {nulls:>4} | Unique: {uniques:>4}")
    
    print("\nüìä Statistical Summary:")
    print(df_crop.describe().round(2))
    
    print("\nüè∑Ô∏è  Labels (Target variable):")
    if 'label' in df_crop.columns:
        label_counts = df_crop['label'].value_counts()
        print(f"  Total classes: {len(label_counts)}")
        print(f"\n  Top 10 crops:")
        for crop, count in label_counts.head(10).items():
            pct = (count / len(df_crop)) * 100
            print(f"    - {crop.ljust(15)}: {count:>4} samples ({pct:>5.2f}%)")
    
    # Mapping v·ªõi 11 th√¥ng s·ªë
    print("\nüîó MAPPING V·ªöI 11 TH√îNG S·ªê H·ªÜ TH·ªêNG:")
    print("-" * 80)
    
    mapping = {
        'N': ('nitrogen', '‚úÖ Direct match'),
        'P': ('phosphorus', '‚úÖ Direct match'),
        'K': ('potassium', '‚úÖ Direct match'),
        'ph': ('ph', '‚úÖ Direct match'),
        'temperature': ('air_temperature', '‚úÖ Direct match (assume air temp)'),
        'humidity': ('air_humidity', '‚úÖ Direct match (assume air humidity)'),
        'rainfall': ('is_raining', '‚ö†Ô∏è  Need convert (mm ‚Üí boolean)')
    }
    
    available = []
    for csv_col, (sys_param, status) in mapping.items():
        if csv_col in df_crop.columns:
            available.append(sys_param)
            print(f"  ‚úÖ {csv_col.ljust(15)} ‚Üí {sys_param.ljust(20)} {status}")
    
    missing = [p for p in REQUIRED_PARAMS if p not in available]
    print(f"\n‚ùå THI·∫æU {len(missing)}/11 th√¥ng s·ªë:")
    for param in missing:
        unit = REQUIRED_PARAMS[param]
        print(f"  - {param.ljust(20)} ({unit})")
    
    print(f"\nüìà Coverage: {len(available)}/11 = {(len(available)/11)*100:.1f}%")
    
    # Data quality checks
    print("\nüîç DATA QUALITY CHECKS:")
    print("-" * 80)
    
    # Check for duplicates
    duplicates = df_crop.duplicated().sum()
    print(f"  ‚Ä¢ Duplicate rows: {duplicates} ({(duplicates/len(df_crop)*100):.2f}%)")
    
    # Check for missing values
    total_nulls = df_crop.isnull().sum().sum()
    print(f"  ‚Ä¢ Missing values: {total_nulls}")
    
    # Check value ranges
    print(f"\n  ‚Ä¢ Value Ranges:")
    for col in ['N', 'P', 'K', 'temperature', 'humidity', 'ph', 'rainfall']:
        if col in df_crop.columns:
            min_val = df_crop[col].min()
            max_val = df_crop[col].max()
            mean_val = df_crop[col].mean()
            print(f"    - {col.ljust(15)}: [{min_val:>7.2f}, {max_val:>7.2f}] | Mean: {mean_val:>7.2f}")
    
    # Check for outliers (simple IQR method)
    print(f"\n  ‚Ä¢ Outliers (IQR method):")
    for col in ['N', 'P', 'K', 'temperature', 'humidity', 'ph', 'rainfall']:
        if col in df_crop.columns:
            Q1 = df_crop[col].quantile(0.25)
            Q3 = df_crop[col].quantile(0.75)
            IQR = Q3 - Q1
            outliers = ((df_crop[col] < (Q1 - 1.5 * IQR)) | (df_crop[col] > (Q3 + 1.5 * IQR))).sum()
            outlier_pct = (outliers / len(df_crop)) * 100
            print(f"    - {col.ljust(15)}: {outliers:>4} outliers ({outlier_pct:>5.2f}%)")
    
    # Save summary
    summary = {
        'dataset': 'Kaggle_Crop_Recommendation',
        'rows': len(df_crop),
        'columns': len(df_crop.columns),
        'coverage': f"{len(available)}/11",
        'coverage_pct': round((len(available)/11)*100, 1),
        'missing_params': missing,
        'duplicates': duplicates,
        'total_nulls': total_nulls,
        'quality_score': '‚≠ê‚≠ê‚≠ê‚≠ê' if total_nulls == 0 and duplicates < 10 else '‚≠ê‚≠ê‚≠ê'
    }
    
else:
    print(f"‚ùå File not found: {crop_file}")
    summary = None

# ============================================================
# 2. UCI - RAISIN DATASET (KI·ªÇM TRA XEM C√ì PH·∫¢I SOIL DATA KH√îNG)
# ============================================================
print("\n\n" + "=" * 80)
print("üìä DATASET 2: Raisin Dataset (UCI)")
print("=" * 80)

raisin_file = "../dataset/Raisin_Dataset/Raisin_Dataset.txt"

if os.path.exists(raisin_file):
    print(f"\n‚ö†Ô∏è  File found: {raisin_file}")
    print("\n‚ö†Ô∏è  PH√ÇN T√çCH: Dataset n√†y l√† v·ªÅ ph√¢n lo·∫°i nho kh√¥ (Raisin classification)")
    print("   ‚Üí KH√îNG LI√äN QUAN ƒë·∫øn soil/agriculture sensor data")
    print("   ‚Üí Columns: Area, MajorAxisLength, MinorAxisLength, etc. (image features)")
    print("\n‚ùå KH√îNG S·ª¨ D·ª§NG CHO AI MODULE N√ÄY")
    print("\nüí° ƒê·ªÅ xu·∫•t: X√≥a th∆∞ m·ª•c 'dataset/Raisin_Dataset' ƒë·ªÉ tr√°nh nh·∫ßm l·∫´n")
    
else:
    print(f"‚ùå File not found: {raisin_file}")

# ============================================================
# 3. T√ìM T·∫ÆT & KHUY·∫æN NGH·ªä
# ============================================================
print("\n\n" + "=" * 80)
print("üìä T√ìM T·∫ÆT & KHUY·∫æN NGH·ªä")
print("=" * 80)

if summary:
    print(f"\n‚úÖ DATASET KH·∫¢ D·ª§NG: Kaggle Crop Recommendation")
    print(f"   ‚Ä¢ S·ªë m·∫´u: {summary['rows']:,} rows")
    print(f"   ‚Ä¢ Coverage: {summary['coverage']} ({summary['coverage_pct']}%)")
    print(f"   ‚Ä¢ Ch·∫•t l∆∞·ª£ng: {summary['quality_score']}")
    print(f"   ‚Ä¢ Duplicates: {summary['duplicates']}")
    print(f"   ‚Ä¢ Missing values: {summary['total_nulls']}")
    
    print(f"\n‚ùå THI·∫æU {len(summary['missing_params'])} TH√îNG S·ªê:")
    for param in summary['missing_params']:
        print(f"   ‚Ä¢ {param}")
    
    print("\n" + "=" * 80)
    print("üéØ CHI·∫æN L∆Ø·ª¢C ƒê·ªÄ XU·∫§T")
    print("=" * 80)
    
    print("\nüìå OPTION 1: Augmentation v·ªõi Domain Knowledge (RECOMMENDED)")
    print("-" * 80)
    print("  T·ª´ 7 th√¥ng s·ªë c√≥ s·∫µn, generate 4 th√¥ng s·ªë thi·∫øu:")
    print()
    print("  1. soil_moisture ‚Üê f(rainfall, humidity, soil_type)")
    print("     ‚Ä¢ N·∫øu rainfall > 100mm ‚Üí moisture = 60-80%")
    print("     ‚Ä¢ N·∫øu rainfall < 50mm  ‚Üí moisture = 20-40%")
    print("     ‚Ä¢ Trung gian: interpolate")
    print()
    print("  2. soil_temperature ‚Üê air_temperature - offset")
    print("     ‚Ä¢ Soil temp th∆∞·ªùng th·∫•p h∆°n air temp 2-5¬∞C")
    print("     ‚Ä¢ Offset = f(moisture, season)")
    print()
    print("  3. conductivity (EC) ‚Üê f(N, P, K, moisture)")
    print("     ‚Ä¢ EC tƒÉng khi NPK cao")
    print("     ‚Ä¢ EC = 100 + (N+P+K)*5 + moisture*10 (simplified)")
    print("     ‚Ä¢ Add Gaussian noise ƒë·ªÉ realistic")
    print()
    print("  4. salt ‚Üê f(EC, moisture)")
    print("     ‚Ä¢ Salt correlate v·ªõi EC")
    print("     ‚Ä¢ Salt = EC * 0.64 (typical conversion)")
    print()
    print("  ‚úÖ ∆Øu ƒëi·ªÉm: Nhanh, c√≥ th·ªÉ implement ngay")
    print("  ‚ö†Ô∏è  Nh∆∞·ª£c ƒëi·ªÉm: Synthetic data, c·∫ßn validate v·ªõi expert")
    
    print("\nüìå OPTION 2: T√¨m th√™m UCI Soil Dataset")
    print("-" * 80)
    print("  Download UCI Soil Dataset th·ª±c s·ª± (kh√¥ng ph·∫£i Raisin):")
    print("  ‚Ä¢ archive.ics.uci.edu/dataset/850/soil")
    print("  ‚Ä¢ C√≥ th·ªÉ cung c·∫•p: EC, Soil Moisture, Soil Temperature")
    print("  ‚Ä¢ Merge v·ªõi Kaggle dataset b·∫±ng clustering/matching")
    print()
    print("  ‚úÖ ∆Øu ƒëi·ªÉm: Real data, accurate")
    print("  ‚ö†Ô∏è  Nh∆∞·ª£c ƒëi·ªÉm: C·∫ßn effort ƒë·ªÉ merge (kh√°c format, scale)")
    
    print("\nüìå OPTION 3: K·∫øt h·ª£p Real Data t·ª´ DB c·ªßa b·∫°n")
    print("-" * 80)
    print("  ‚Ä¢ D√πng Kaggle l√†m base (2,200 samples)")
    print("  ‚Ä¢ Augment synthetic ƒë·ªÉ c√≥ 11 fields")
    print("  ‚Ä¢ Fine-tune model v·ªõi real data t·ª´ PostgreSQL")
    print("  ‚Ä¢ Transfer learning approach")
    print()
    print("  ‚úÖ ∆Øu ƒëi·ªÉm: Model fit v·ªõi data th·ª±c c·ªßa b·∫°n")
    print("  ‚ö†Ô∏è  Nh∆∞·ª£c ƒëi·ªÉm: C·∫ßn √≠t nh·∫•t 200-500 real samples")

print("\n" + "=" * 80)
print("‚ùì B·∫†N MU·ªêN TH·ª∞C HI·ªÜN OPTION N√ÄO?")
print("=" * 80)
print("  1. Option 1 - Augmentation (Fastest, c√≥ th·ªÉ l√†m ngay)")
print("  2. Option 2 - Download UCI Soil Dataset th·∫≠t")
print("  3. Option 3 - ƒê·ª£i thu th·∫≠p real data t·ª´ IoT")
print("  4. Hybrid - Option 1 + Option 3 (train synthetic ‚Üí fine-tune real)")
print()
print("üí° Khuy·∫øn ngh·ªã: B·∫ÆT ƒê·∫¶U V·ªöI OPTION 1 ho·∫∑c HYBRID")
print("=" * 80)

