"""
UNIFIED BACKEND - PORT 8080 (INTERNAL)

G·ªôp 3 services:
1. Flask Data Ingest API
2. Flask Auth API
3. FastAPI AI Service

Ch·∫°y d∆∞·ªõi 1 process duy nh·∫•t
"""

from flask import Flask, request, jsonify
from flask_cors import CORS
import os
import psycopg2
from psycopg2.extras import RealDictCursor
from datetime import datetime, timezone, timedelta
from dotenv import load_dotenv
import logging
import sys

# FastAPI imports
from fastapi import FastAPI, HTTPException
from fastapi.middleware.cors import CORSMiddleware as FastAPICORS
from fastapi.responses import JSONResponse
import uvicorn
from threading import Thread
import time

# Google Gemini AI (install: pip install google-generativeai tenacity)
try:
    import google.generativeai as genai
    from tenacity import retry, stop_after_attempt, wait_exponential, retry_if_exception_type
    GEMINI_AVAILABLE = True
except ImportError:
    GEMINI_AVAILABLE = False
    print("‚ö†Ô∏è  google-generativeai not installed")

# AI Service imports
sys.path.append(os.path.join(os.path.dirname(__file__), 'ai_service'))
from ai_service.schemas import SoilDataInput, AIAnalysisResponse, HealthCheckResponse, DailyAggregateInput, DailyAnalysisResponse
from ai_service.models_loader import get_model_registry
from ai_service.inference import analyze_soil, analyze_aggregated_data
from ai_service.daily_aggregator import aggregate_daily_data, save_daily_insight, push_to_blockchain

# Auth imports
from auth_routes import auth_bp
from dashboard_routes import dashboard_bp

# Load environment
load_dotenv()

# Setup logging
logging.basicConfig(
    level=logging.INFO,
    format='%(asctime)s - %(name)s - %(levelname)s - %(message)s'
)
logger = logging.getLogger(__name__)

# ============================================================
# GEMINI AI CONFIGURATION
# ============================================================
GEMINI_API_KEY = os.getenv('GEMINI_API_KEY', 'AIzaSyAeE5mtJWbCa9JiL-rxB78c4HU7Bx7yOvM')
GEMINI_MODEL_NAME = 'gemini-2.5-pro'

if GEMINI_AVAILABLE and GEMINI_API_KEY:
    try:
        genai.configure(api_key=GEMINI_API_KEY)
        gemini_model = genai.GenerativeModel(GEMINI_MODEL_NAME)
        logger.info(f"‚úÖ Gemini AI initialized: {GEMINI_MODEL_NAME}")
    except Exception as e:
        logger.error(f"‚ùå Failed to initialize Gemini: {e}")
        gemini_model = None
else:
    gemini_model = None
    if not GEMINI_AVAILABLE:
        logger.warning("‚ö†Ô∏è  Gemini SDK not installed - using rule-based AI")
    elif not GEMINI_API_KEY:
        logger.warning("‚ö†Ô∏è  GEMINI_API_KEY not set - using rule-based AI")

# Retry decorator for Gemini API calls
@retry(
    stop=stop_after_attempt(3),
    wait=wait_exponential(multiplier=1, min=2, max=10),
    retry=retry_if_exception_type(Exception),
    reraise=True
)
def call_gemini_with_retry(prompt: str) -> str:
    """Call Gemini API with exponential backoff retry"""
    if not gemini_model:
        raise Exception("Gemini model not initialized")
    
    response = gemini_model.generate_content(prompt)
    return response.text

# ============================================================
# FLASK APP (Data Ingest + Auth + Dashboard)
# ============================================================

flask_app = Flask(__name__)
CORS(flask_app)

# Register blueprints
flask_app.register_blueprint(auth_bp)
flask_app.register_blueprint(dashboard_bp)

# Database helper
def get_db_conn():
    dsn = os.getenv("DATABASE_URL")
    if dsn:
        return psycopg2.connect(dsn)
    return psycopg2.connect(
        host=os.getenv("PGHOST", "36.50.134.107"),
        port=int(os.getenv("PGPORT", "6000")),
        dbname=os.getenv("PGDATABASE", "db_iot_sensor"),
        user=os.getenv("PGUSER", "admin"),
        password=os.getenv("PGPASSWORD", "admin123"),
    )

def normalize_measured_at_vn(payload: dict) -> str | None:
    created_at = payload.get("created_at")
    if isinstance(created_at, str) and len(created_at) >= 19:
        return created_at[:19]

    ts = payload.get("timestamp")
    if ts is None:
        vn = datetime.now(timezone.utc) + timedelta(hours=7)
        return vn.strftime("%Y-%m-%d %H:%M:%S")

    if isinstance(ts, (int, float)):
        dt_utc = datetime.fromtimestamp(ts, tz=timezone.utc)
        vn = dt_utc + timedelta(hours=7)
        return vn.strftime("%Y-%m-%d %H:%M:%S")

    if isinstance(ts, str):
        try:
            dt = datetime.strptime(ts, "%a, %d %b %Y %H:%M:%S GMT").replace(tzinfo=timezone.utc)
            vn = dt + timedelta(hours=7)
            return vn.strftime("%Y-%m-%d %H:%M:%S")
        except Exception:
            pass
        if len(ts) >= 19 and ts[4] == '-' and ts[7] == '-' and ts[13] == ':' and ts[16] == ':':
            return ts[:19]

    return None


# ====== FLASK ROUTES ======

@flask_app.route("/api/data", methods=["GET"])
def data_info():
    """GET /api/data - Show API information"""
    return jsonify({
        "service": "IoT Data Ingest API",
        "version": "2.0 (Unified)",
        "status": "running",
        "endpoint": "/api/data",
        "method": "POST",
        "description": "Endpoint for ESP8266/ESP32 to send sensor data",
        "required_fields": [
            "temperature", "humidity", "conductivity", "ph",
            "nitrogen", "phosphorus", "potassium", "salt",
            "air_temperature", "air_humidity", "is_raining"
        ],
        "example": {
            "temperature": 25.5,
            "humidity": 60.0,
            "conductivity": 500,
            "ph": 6.5,
            "nitrogen": 50,
            "phosphorus": 30,
            "potassium": 40,
            "salt": 100,
            "air_temperature": 28.0,
            "air_humidity": 65.0,
            "is_raining": False
        }
    })

@flask_app.route("/api/data", methods=["POST"])
def receive_data():
    try:
        data = request.get_json(silent=True) or {}
        
        soil_temperature = data.get("temperature")
        soil_moisture = data.get("humidity")
        conductivity = data.get("conductivity")
        ph = data.get("ph")
        nitrogen = data.get("nitrogen")
        phosphorus = data.get("phosphorus")
        potassium = data.get("potassium")
        salt = data.get("salt")
        air_temperature = data.get("air_temperature")
        air_humidity = data.get("air_humidity")
        is_raining = data.get("is_raining")
        
        required_fields = {
            "soil_temperature": soil_temperature,
            "soil_moisture": soil_moisture,
            "conductivity": conductivity,
            "ph": ph,
            "nitrogen": nitrogen,
            "phosphorus": phosphorus,
            "potassium": potassium,
            "salt": salt,
            "air_temperature": air_temperature,
            "air_humidity": air_humidity,
            "is_raining": is_raining
        }
        
        missing = [k for k, v in required_fields.items() if v is None]
        if missing:
            return jsonify({
                "status": "error", 
                "message": f"Missing required fields: {', '.join(missing)}"
            }), 400
        
        if isinstance(is_raining, bool):
            is_raining_bool = is_raining
        elif isinstance(is_raining, str):
            is_raining_bool = is_raining.lower() == "true"
        else:
            is_raining_bool = bool(is_raining)

        measured_at_vn = normalize_measured_at_vn(data)
        if not measured_at_vn:
            return jsonify({"status": "error", "message": "Invalid timestamp/created_at"}), 400

        with get_db_conn() as conn:
            with conn.cursor() as cur:
                cur.execute(
                    """
                    INSERT INTO sensor_readings (
                        measured_at_vn,
                        soil_temperature_c, soil_moisture_pct,
                        conductivity_us_cm, ph_value,
                        nitrogen_mg_kg, phosphorus_mg_kg, potassium_mg_kg, salt_mg_l,
                        air_temperature_c, air_humidity_pct, is_raining
                    )
                    VALUES (%s, %s, %s, %s, %s, %s, %s, %s, %s, %s, %s, %s)
                    ON CONFLICT (measured_at_vn) DO NOTHING
                    """,
                    (
                        measured_at_vn,
                        float(soil_temperature),
                        float(soil_moisture),
                        int(conductivity),
                        float(ph),
                        int(nitrogen),
                        int(phosphorus),
                        int(potassium),
                        int(salt),
                        float(air_temperature),
                        float(air_humidity),
                        is_raining_bool
                    ),
                )
                conn.commit()

        # Callback blockchain bridge via internal endpoint
        bridge_url = "http://localhost:3000/bridgePending"
        bridge_result = None
        try:
            import urllib.request
            import json
            req = urllib.request.Request(
                bridge_url,
                data=json.dumps({"limit": 1}).encode("utf-8"),
                headers={"Content-Type": "application/json"},
                method="POST",
            )
            # Increased timeout to 30s for blockchain confirmation
            with urllib.request.urlopen(req, timeout=30) as resp:
                bridge_result = {"status": resp.status, "confirmed": True}
        except Exception as e:
            bridge_result = {"error": str(e), "confirmed": False}

        return jsonify({
            "status": "success",
            "measured_at_vn": measured_at_vn,
            "bridge": bridge_result,
        }), 200
    except Exception as e:
        return jsonify({"status": "error", "message": str(e)}), 500


@flask_app.route("/api/latest", methods=["GET"])
def api_latest():
    try:
        with get_db_conn() as conn:
            with conn.cursor(cursor_factory=RealDictCursor) as cur:
                cur.execute(
                    """
                    SELECT id,
                           soil_temperature_c as soil_temperature,
                           soil_moisture_pct as soil_moisture,
                           conductivity_us_cm as conductivity,
                           ph_value as ph,
                           nitrogen_mg_kg as nitrogen,
                           phosphorus_mg_kg as phosphorus,
                           potassium_mg_kg as potassium,
                           salt_mg_l as salt,
                           air_temperature_c as air_temperature,
                           air_humidity_pct as air_humidity,
                           is_raining,
                           measured_at_vn, created_at_vn, onchain_status
                    FROM sensor_readings
                    ORDER BY id DESC
                    LIMIT 1
                    """
                )
                row = cur.fetchone()
                if not row:
                    return jsonify({"message": "no data"}), 200
                row["status"] = row.get("onchain_status") or "pending"
                row["created_at"] = row.get("created_at_vn")
                row["timestamp"] = row.get("measured_at_vn")
                return jsonify(row), 200
    except Exception as e:
        return jsonify({"error": str(e)}), 500


@flask_app.route("/api/history", methods=["GET"])
def api_history():
    try:
        limit = min(int(request.args.get("limit", 100)), 1000)
        with get_db_conn() as conn:
            with conn.cursor(cursor_factory=RealDictCursor) as cur:
                cur.execute(
                    """
                    SELECT id,
                           soil_temperature_c as soil_temperature,
                           soil_moisture_pct as soil_moisture,
                           conductivity_us_cm as conductivity,
                           ph_value as ph,
                           nitrogen_mg_kg as nitrogen,
                           phosphorus_mg_kg as phosphorus,
                           potassium_mg_kg as potassium,
                           salt_mg_l as salt,
                           air_temperature_c as air_temperature,
                           air_humidity_pct as air_humidity,
                           is_raining,
                           measured_at_vn as timestamp,
                           onchain_status as status,
                           created_at_vn as created_at
                    FROM sensor_readings
                    ORDER BY id DESC
                    LIMIT %s
                    """,
                    (limit,),
                )
                rows = cur.fetchall()
                return jsonify({"count": len(rows), "data": rows}), 200
    except Exception as e:
        return jsonify({"error": str(e)}), 500


@flask_app.route("/api/health", methods=["GET"])
def flask_health():
    return jsonify({
        "service": "Flask API",
        "status": "ok",
        "timestamp": datetime.now().isoformat()
    }), 200


# ============================================================
# DASHBOARD ROUTES
# ============================================================

@flask_app.route("/api/dashboard/overview", methods=["GET"])
def dashboard_overview():
    """Dashboard overview statistics for last 30 days"""
    try:
        with get_db_conn() as conn:
            with conn.cursor() as cur:
                # Daily insights stats
                cur.execute("""
                    SELECT 
                        AVG(soil_health_score) as avg_health,
                        COUNT(id) as total_insights,
                        COUNT(CASE WHEN blockchain_status = 'confirmed' THEN 1 END) as verified_count,
                        COUNT(CASE WHEN has_anomaly = TRUE THEN 1 END) as anomaly_count
                    FROM daily_insights
                    WHERE date_vn >= CURRENT_DATE - INTERVAL '30 days'
                """)
                insights_row = cur.fetchone()
                
                # Total IoT records
                cur.execute("""
                    SELECT COUNT(*) as total_iot
                    FROM sensor_readings
                    WHERE measured_at_vn >= NOW() - INTERVAL '30 days'
                """)
                iot_row = cur.fetchone()
                
                stats = {
                    "avg_soil_health": round(float(insights_row[0] or 0), 1),
                    "total_iot_records": int(iot_row[0] or 0),
                    "verified_daily_insights": int(insights_row[2] or 0),
                    "total_daily_insights": int(insights_row[1] or 0),
                    "anomalies_detected": int(insights_row[3] or 0),
                    "last_updated": datetime.now(timezone.utc).isoformat() + 'Z'
                }
                
                return jsonify({
                    "success": True,
                    "stats": stats,
                    "period": "last_30_days"
                }), 200
    except Exception as e:
        print(f"‚ùå Dashboard overview error: {e}")
        return jsonify({"success": False, "error": str(e)}), 500


@flask_app.route("/api/dashboard/realtime-iot", methods=["GET"])
def dashboard_realtime_iot():
    """Latest IoT sensor reading + 24h trend"""
    try:
        hours = int(request.args.get('hours', 24))
        
        with get_db_conn() as conn:
            with conn.cursor() as cur:
                # Latest sensor reading (ORDER BY created_at_vn DESC to get real IoT data by insert time)
                cur.execute("""
                    SELECT 
                        measured_at_vn, soil_temperature_c, soil_moisture_pct,
                        ph_value, nitrogen_mg_kg, phosphorus_mg_kg, potassium_mg_kg,
                        salt_mg_l, air_temperature_c, air_humidity_pct, is_raining,
                        onchain_status, conductivity_us_cm
                    FROM sensor_readings
                    ORDER BY created_at_vn DESC
                    LIMIT 1
                """)
                latest_row = cur.fetchone()
                
                if not latest_row:
                    return jsonify({"success": False, "error": "No sensor data available"}), 404
                
                latest = {
                    "measured_at": latest_row[0].strftime('%Y-%m-%d %H:%M:%S') if latest_row[0] else None,
                    "soil_temperature_c": float(latest_row[1]) if latest_row[1] is not None else 0,
                    "soil_moisture_pct": float(latest_row[2]) if latest_row[2] is not None else 0,
                    "ph_value": float(latest_row[3]) if latest_row[3] is not None else 0,
                    "nitrogen_mg_kg": float(latest_row[4]) if latest_row[4] is not None else 0,
                    "phosphorus_mg_kg": float(latest_row[5]) if latest_row[5] is not None else 0,
                    "potassium_mg_kg": float(latest_row[6]) if latest_row[6] is not None else 0,
                    "salt_mg_l": float(latest_row[7]) if latest_row[7] is not None else 0,
                    "air_temperature_c": float(latest_row[8]) if latest_row[8] is not None else 0,
                    "air_humidity_pct": float(latest_row[9]) if latest_row[9] is not None else 0,
                    "is_raining": bool(latest_row[10]),
                    "onchain_status": latest_row[11],
                    "conductivity_us_cm": float(latest_row[12]) if latest_row[12] is not None else 0
                }
                
                # Hourly trend
                cur.execute("""
                    SELECT 
                        DATE_TRUNC('hour', measured_at_vn) as hour,
                        AVG(soil_temperature_c), AVG(soil_moisture_pct), AVG(ph_value),
                        AVG(nitrogen_mg_kg), AVG(phosphorus_mg_kg), AVG(potassium_mg_kg)
                    FROM sensor_readings
                    WHERE measured_at_vn >= NOW() - INTERVAL '%s hours'
                    GROUP BY hour
                    ORDER BY hour ASC
                """ % hours)
                
                trend_24h = []
                for row in cur.fetchall():
                    trend_24h.append({
                        "time": row[0].strftime('%Y-%m-%d %H:%M') if row[0] else None,
                        "temp": round(float(row[1] or 0), 1),
                        "moisture": round(float(row[2] or 0), 1),
                        "ph": round(float(row[3] or 0), 1),
                        "nitrogen": round(float(row[4] or 0), 1),
                        "phosphorus": round(float(row[5] or 0), 1),
                        "potassium": round(float(row[6] or 0), 1)
                    })
                
                return jsonify({
                    "success": True,
                    "latest": latest,
                    "trend_24h": trend_24h,
                    "hours": hours
                }), 200
    except Exception as e:
        print(f"‚ùå Realtime IoT error: {e}")
        return jsonify({"success": False, "error": str(e)}), 500


@flask_app.route("/api/dashboard/ai-history", methods=["GET"])
def dashboard_ai_history():
    """Daily AI insights for last N days"""
    try:
        days = int(request.args.get('days', 30))
        
        with get_db_conn() as conn:
            with conn.cursor() as cur:
                cur.execute("""
                    SELECT 
                        id, date_vn, recommended_crop, crop_confidence,
                        soil_health_score, soil_health_rating, has_anomaly,
                        blockchain_status, blockchain_tx_hash, blockchain_pushed_at,
                        recommendations_json, total_readings, created_at
                    FROM daily_insights
                    WHERE date_vn >= CURRENT_DATE - INTERVAL '%s days'
                    ORDER BY date_vn DESC
                """ % days)
                
                insights = []
                for row in cur.fetchall():
                    insights.append({
                        "id": row[0],
                        "date": row[1].strftime('%Y-%m-%d') if row[1] else None,
                        "recommended_crop": row[2],
                        "confidence": int(row[3] or 0),
                        "soil_health_score": int(row[4] or 0),
                        "health_rating": row[5],
                        "is_anomaly_detected": bool(row[6]),
                        "blockchain_status": row[7],
                        "blockchain_tx_hash": row[8],
                        "blockchain_pushed_at": row[9].strftime('%Y-%m-%d %H:%M:%S') if row[9] else None,
                        "recommendations": row[10],
                        "sample_count": int(row[11] or 0),
                        "created_at": row[12].strftime('%Y-%m-%d %H:%M:%S') if row[12] else None
                    })
                
                return jsonify({
                    "success": True,
                    "insights": insights,
                    "total": len(insights),
                    "days": days
                }), 200
    except Exception as e:
        print(f"‚ùå AI history error: {e}")
        return jsonify({"success": False, "error": str(e)}), 500


# ============================================================
# ZALO INTEGRATION
# ============================================================

@flask_app.route("/api/auth/zalo/link-account", methods=["POST"])
def link_zalo_account():
    """
    Link Zalo ID with user account using verification token
    
    This endpoint is called after user:
    1. Receives Zalo message with linking link (created by n8n)
    2. Clicks the link and signs in to web
    3. Confirms on web to complete linking
    
    Request body:
    {
        "token": "abc123xyz...",  # Token from zalo_link_sessions table
        "user_id": 1              # Currently logged-in user ID (from auth)
    }
    
    Response:
    {
        "success": true,
        "message": "T√†i kho·∫£n Zalo ƒë√£ ƒë∆∞·ª£c li√™n k·∫øt th√†nh c√¥ng!",
        "zalo_id": "123456789",
        "user_id": 1,
        "full_name": "Nguyen Van A"
    }
    """
    try:
        data = request.get_json(silent=True) or {}
        token = data.get('token')
        user_id = data.get('user_id')
        
        if not token or not user_id:
            return jsonify({
                'success': False,
                'error': 'Missing required fields: token, user_id'
            }), 400
        
        conn = get_db_conn()
        cur = conn.cursor()
        
        try:
            # 1. Verify token exists and get zalo_id from it
            cur.execute("""
                SELECT id, expires_at, is_used, zalo_id
                FROM zalo_link_sessions
                WHERE token = %s
            """, (token,))
            
            session_row = cur.fetchone()
            
            if not session_row:
                cur.close()
                conn.close()
                return jsonify({
                    'success': False,
                    'error': 'Token kh√¥ng h·ª£p l·ªá ho·∫∑c kh√¥ng t·ªìn t·∫°i'
                }), 404
            
            session_id, expires_at, is_used, zalo_id = session_row
            
            # Check if token already used
            if is_used:
                cur.close()
                conn.close()
                return jsonify({
                    'success': False,
                    'error': 'Token ƒë√£ ƒë∆∞·ª£c s·ª≠ d·ª•ng r·ªìi'
                }), 400
            
            # Check if token expired (comparing UTC times with timezone)
            from datetime import datetime as dt
            now_utc = dt.now(timezone.utc)
            if now_utc > expires_at:
                cur.close()
                conn.close()
                return jsonify({
                    'success': False,
                    'error': 'Token ƒë√£ h·∫øt h·∫°n (5 ph√∫t). Vui l√≤ng y√™u c·∫ßu li√™n k·∫øt l·∫°i.'
                }), 400
            
            # 2. Check if this zalo_chat_id is already linked to another user
            cur.execute("""
                SELECT id FROM users WHERE zalo_chat_id = %s AND id != %s
            """, (zalo_id, user_id))
            
            existing = cur.fetchone()
            if existing:
                cur.close()
                conn.close()
                return jsonify({
                    'success': False,
                    'error': 'Zalo ID n√†y ƒë√£ ƒë∆∞·ª£c li√™n k·∫øt v·ªõi t√†i kho·∫£n kh√°c'
                }), 409
            
            # 3. Update user with zalo_chat_id
            cur.execute("""
                UPDATE users
                SET zalo_chat_id = %s,
                    updated_at_vn = NOW() AT TIME ZONE 'Asia/Ho_Chi_Minh'
                WHERE id = %s
                RETURNING id, full_name, zalo_chat_id
            """, (zalo_id, user_id))
            
            result = cur.fetchone()
            
            if not result:
                cur.close()
                conn.close()
                return jsonify({
                    'success': False,
                    'error': 'User kh√¥ng t·ªìn t·∫°i'
                }), 404
            
            user_id_returned, full_name, zalo_chat_id_linked = result
            
            # 4. Mark session token as used and link to user
            cur.execute("""
                UPDATE zalo_link_sessions
                SET is_used = TRUE,
                    user_id = %s
                WHERE id = %s
            """, (user_id, session_id))
            
            conn.commit()
            
            logger.info(f"‚úÖ Zalo account linked!")
            logger.info(f"   User: {full_name} (ID: {user_id_returned})")
            logger.info(f"   Zalo ID: {zalo_chat_id_linked}")
            
            return jsonify({
                'success': True,
                'message': 'T√†i kho·∫£n Zalo ƒë√£ ƒë∆∞·ª£c li√™n k·∫øt th√†nh c√¥ng!',
                'zalo_id': zalo_chat_id_linked,
                'user_id': user_id_returned,
                'full_name': full_name
            }), 200
            
        finally:
            cur.close()
            conn.close()
        
    except Exception as e:
        logger.error(f"‚ùå Link Zalo error: {e}", exc_info=True)
        return jsonify({
            'success': False,
            'error': str(e)
        }), 500


# ============================================================
# AI CHAT & ANALYSIS
# ============================================================

@flask_app.route("/api/ai/chat", methods=["POST"])
def flask_ai_chat():
    """
    AI Chat endpoint - READS DATABASE REAL-TIME for latest sensor data
    """
    try:
        data = request.get_json(silent=True) or {}
        message = data.get('message', '')
        
        # QUERY DATABASE FOR REAL-TIME DATA
        logger.info(f"üí¨ AI Chat request: {message[:50]}...")
        try:
            with get_db_conn() as conn:
                with conn.cursor(cursor_factory=RealDictCursor) as cur:
                    cur.execute("""
                        SELECT 
                            soil_temperature_c as soil_temperature,
                            soil_moisture_pct as soil_moisture,
                            ph_value as ph,
                            nitrogen_mg_kg as nitrogen,
                            phosphorus_mg_kg as phosphorus,
                            potassium_mg_kg as potassium,
                            air_humidity_pct as air_humidity,
                            air_temperature_c as air_temperature,
                            salt_mg_l as salt,
                            measured_at_vn
                        FROM sensor_readings 
                        ORDER BY measured_at_vn DESC 
                        LIMIT 1
                    """)
                    latest = cur.fetchone()
                    
                    if not latest:
                        logger.warning("‚ö†Ô∏è No sensor data found in database")
                        return jsonify({"error": "Kh√¥ng c√≥ d·ªØ li·ªáu c·∫£m bi·∫øn"}), 404
                    
                    # Extract real-time values from database
                    temp = float(latest['soil_temperature'] or 0)
                    moisture = float(latest['soil_moisture'] or 0)
                    ph = float(latest['ph'] or 0)
                    nitrogen = int(latest['nitrogen'] or 0)
                    phosphorus = int(latest['phosphorus'] or 0)
                    potassium = int(latest['potassium'] or 0)
                    humidity = float(latest['air_humidity'] or 0)
                    
                    logger.info(f"üìä Real-time data from DB: temp={temp}¬∞C, moisture={moisture}%, pH={ph}, NPK=({nitrogen},{phosphorus},{potassium})")
                    
        except Exception as db_error:
            logger.error(f"‚ùå Database error: {db_error}")
            return jsonify({"error": "L·ªói ƒë·ªçc database"}), 500
        
        # ============================================================
        # TRY GEMINI AI FIRST (with retry logic)
        # ============================================================
        if gemini_model:
            try:
                logger.info("ü§ñ Using Gemini AI for response...")
                
                # Build comprehensive prompt for Gemini
                gemini_prompt = f"""B·∫°n l√† chuy√™n gia n√¥ng nghi·ªáp th√¥ng minh, th√¢n thi·ªán v√† chuy√™n nghi·ªáp. H√£y tr·∫£ l·ªùi c√¢u h·ªèi c·ªßa ng∆∞·ªùi n√¥ng d√¢n.

**C√¢u h·ªèi:** {message}

**D·ªØ li·ªáu c·∫£m bi·∫øn hi·ªán t·∫°i (REAL-TIME t·ª´ database):**
- Nhi·ªát ƒë·ªô ƒë·∫•t: {temp}¬∞C
- ƒê·ªô ·∫©m ƒë·∫•t: {moisture}%
- pH ƒë·∫•t: {ph}
- Nitrogen (N): {nitrogen} mg/kg
- Phosphorus (P): {phosphorus} mg/kg
- Potassium (K): {potassium} mg/kg
- ƒê·ªô ·∫©m kh√¥ng kh√≠: {humidity}%

**H∆∞·ªõng d·∫´n tr·∫£ l·ªùi:**
1. G·ªçi ng∆∞·ªùi d√πng l√† "b√°c" (th√¢n thi·ªán, ki·ªÉu n√¥ng d√¢n Vi·ªát Nam)
2. Ph√¢n t√≠ch C·ª§ TH·ªÇ d·ª±a tr√™n d·ªØ li·ªáu TH·ª∞C T·∫æ tr√™n
3. So s√°nh v·ªõi ng∆∞·ª°ng t·ªëi ∆∞u:
   - Nhi·ªát ƒë·ªô ƒë·∫•t: 20-30¬∞C
   - ƒê·ªô ·∫©m ƒë·∫•t: 40-70%
   - pH: 6.0-7.5
   - NPK: N‚â•40, P‚â•30, K‚â•150 mg/kg
4. ƒê∆∞a ra l·ªùi khuy√™n H√ÄNH ƒê·ªòNG c·ª• th·ªÉ (b√≥n ph√¢n g√¨, bao nhi√™u kg/s√†o)
5. N·∫øu h·ªèi v·ªÅ c√¢y tr·ªìng ‚Üí ƒë·ªÅ xu·∫•t 2-3 lo·∫°i c√¢y PH√ô H·ª¢P v·ªõi ƒëi·ªÅu ki·ªán hi·ªán t·∫°i
6. D√πng emoji ph√π h·ª£p (‚úÖ ‚ö†Ô∏è üå°Ô∏è üíß üå± üçÖ ü•¨ üå∂Ô∏è)
7. TR·∫¢ L·ªúI NG·∫ÆN G·ªåN, D·ªÑ HI·ªÇU (kh√¥ng qu√° 200 t·ª´)

H√£y tr·∫£ l·ªùi:"""

                # Call Gemini with retry
                gemini_response = call_gemini_with_retry(gemini_prompt)
                logger.info(f"‚úÖ Gemini response received ({len(gemini_response)} chars)")
                
                return jsonify({"response": gemini_response}), 200
                
            except Exception as gemini_error:
                logger.error(f"‚ö†Ô∏è  Gemini API failed: {gemini_error}")
                logger.info("üîÑ Falling back to rule-based AI...")
                # Continue to rule-based fallback below
        
        # ============================================================
        # FALLBACK: RULE-BASED AI (if Gemini not available or failed)
        # ============================================================
        logger.info("üìã Using rule-based AI for response...")
        
        # Detect question type - MORE INTELLIGENT
        is_crop_recommendation = any(word in message.lower() for word in [
            'tr·ªìng', 'c√¢y', 'gieo', 'crop', 'plant', 'lo·∫°i c√¢y', 'lo·∫°i c√¥ng', 
            'ph√π h·ª£p', 'n√™n tr·ªìng', 'th√≠ch h·ª£p', 'suitable'
        ])
        
        # Detect if user asking about combination/comparison (e.g., "nhi·ªát ƒë·ªô + NPK")
        is_combination_question = any(phrase in message.lower() for phrase in [
            'v·ªõi', 'c√πng', 'th√¨', '·ªïn kh√¥ng', '·ªïn ko', 'ƒë∆∞·ª£c kh√¥ng', 'ƒë∆∞·ª£c ko',
            'c√≥ t·ªët', 'c√≥ ·ªïn', 'nh∆∞ v·∫≠y', 'nh∆∞ th·∫ø', 'th·∫ø n√†y'
        ]) and (
            ('nhi·ªát ƒë·ªô' in message.lower() or 'temperature' in message.lower()) or
            ('npk' in message.lower()) or
            ('ph' in message.lower()) or
            ('ƒë·ªô ·∫©m' in message.lower())
        )
        
        is_general_chat = any(word in message.lower() for word in [
            'v∆∞·ªùn', 't·ªïng quan', 't√¨nh h√¨nh', 'th·∫ø n√†o', 'nh∆∞ n√†o', 'overview'
        ]) and not any(word in message for word in ['Nhi·ªát ƒë·ªô', 'ƒê·ªô ·∫©m', 'pH', 'NPK'])
        
        # Detect which metric is being analyzed from message
        metric_focused = None
        if 'Nhi·ªát ƒë·ªô ƒë·∫•t' in message or 'temperature' in message.lower():
            metric_focused = 'temperature'
        elif 'ƒê·ªô ·∫©m ƒë·∫•t' in message or 'moisture' in message.lower():
            metric_focused = 'moisture'
        elif 'pH' in message or 'ph' in message.lower():
            metric_focused = 'ph'
        elif 'Nitrogen' in message or 'nitrogen' in message.lower() or 'NPK' in message:
            metric_focused = 'nitrogen'
        elif 'Phosphorus' in message or 'phosphorus' in message.lower():
            metric_focused = 'phosphorus'
        elif 'Potassium' in message or 'potassium' in message.lower() or 'Kali' in message:
            metric_focused = 'potassium'
        elif 'ƒê·ªô ·∫©m kh√¥ng kh√≠' in message or 'humidity' in message.lower():
            metric_focused = 'humidity'
        
        # Build response based on focused metric
        response = ""
        
        # PRIORITY 1: Combination questions (e.g., "nhi·ªát ƒë·ªô + NPK ·ªïn kh√¥ng?")
        if is_combination_question and not metric_focused:
            response = "ƒê·ªÉ ch√°u ph√¢n t√≠ch ƒëi·ªÅu ki·ªán t·ªïng h·ª£p cho b√°c nh√©!\n\n"
            
            # Comprehensive analysis
            temp_status = "‚úÖ t·ªët" if 20 <= temp <= 30 else "‚ö†Ô∏è c·∫ßn ƒëi·ªÅu ch·ªânh"
            ph_status = "‚úÖ l√Ω t∆∞·ªüng" if 6.0 <= ph <= 7.5 else "‚ö†Ô∏è c·∫ßn ƒëi·ªÅu ch·ªânh"
            moisture_status = "‚úÖ t·ªët" if 40 <= moisture <= 70 else "‚ö†Ô∏è c·∫ßn ƒëi·ªÅu ch·ªânh"
            npk_status = "‚úÖ ƒë·∫ßy ƒë·ªß" if (nitrogen >= 40 and phosphorus >= 30 and potassium >= 150) else "‚ö†Ô∏è thi·∫øu"
            
            response += f"**üìä T·ªïng quan ƒëi·ªÅu ki·ªán:**\n"
            response += f"- Nhi·ªát ƒë·ªô ƒë·∫•t: **{temp}¬∞C** ({temp_status})\n"
            response += f"- pH ƒë·∫•t: **{ph}** ({ph_status})\n"
            response += f"- ƒê·ªô ·∫©m ƒë·∫•t: **{moisture}%** ({moisture_status})\n"
            response += f"- NPK: N={nitrogen}, P={phosphorus}, K={potassium} ({npk_status})\n\n"
            
            # Overall assessment
            good_count = sum([
                20 <= temp <= 30,
                6.0 <= ph <= 7.5,
                40 <= moisture <= 70,
                nitrogen >= 40 and phosphorus >= 30 and potassium >= 150
            ])
            
            if good_count == 4:
                response += "**üåü ƒê√ÅNH GI√Å: ƒê·∫§T C·ª∞C K·ª≤ PH√ô H·ª¢P!**\n\n"
                response += "V·ªõi ƒëi·ªÅu ki·ªán nh∆∞ n√†y, b√°c c√≥ th·ªÉ tr·ªìng:\n"
                response += "- üçÖ **C√† chua**: NPK v√† nhi·ªát ƒë·ªô l√Ω t∆∞·ªüng, thu ho·∫°ch cao\n"
                response += "- ü•í **D∆∞a leo, d∆∞a chu·ªôt**: Kali cao, qu·∫£ to ng·ªçt\n"
                response += "- üå∂Ô∏è **·ªöt**: ƒêi·ªÅu ki·ªán ho√†n h·∫£o, ra tr√°i li√™n t·ª•c\n"
                response += "- ü•¨ **Rau xanh**: Sinh tr∆∞·ªüng nhanh, ch·∫•t l∆∞·ª£ng t·ªët\n\n"
                response += "üí° **L·ªùi khuy√™n:** Ti·∫øp t·ª•c duy tr√¨ ƒëi·ªÅu ki·ªán n√†y, ƒë·ªãnh k·ª≥ b√≥n ph√¢n b·ªï sung v√† t∆∞·ªõi ƒë·ªÅu. B√°c s·∫Ω c√≥ v·ª• m√πa b·ªôi thu ƒë√≥!"
            elif good_count >= 2:
                response += "**‚úÖ ƒê√ÅNH GI√Å: ƒê·∫§T PH√ô H·ª¢P**\n\n"
                issues = []
                if not (20 <= temp <= 30):
                    if temp < 20:
                        issues.append(f"- Nhi·ªát ƒë·ªô **{temp}¬∞C** h∆°i th·∫•p ‚Üí Che ph·ªß, t∆∞·ªõi n∆∞·ªõc ·∫•m v√†o tr∆∞a")
                    else:
                        issues.append(f"- Nhi·ªát ƒë·ªô **{temp}¬∞C** h∆°i cao ‚Üí Che b√≥ng m√°t, t∆∞·ªõi s√°ng s·ªõm/chi·ªÅu m√°t")
                
                if not (6.0 <= ph <= 7.5):
                    if ph < 6.0:
                        issues.append(f"- pH **{ph}** qu√° chua ‚Üí R·∫£i v√¥i b·ªôt 200-300kg/ha")
                    else:
                        issues.append(f"- pH **{ph}** qu√° ki·ªÅm ‚Üí B√≥n ph√¢n l∆∞u hu·ª≥nh, ph√¢n chu·ªìng")
                
                if not (40 <= moisture <= 70):
                    if moisture < 40:
                        issues.append(f"- ƒê·ªô ·∫©m **{moisture}%** kh√¥ ‚Üí T∆∞·ªõi n∆∞·ªõc ngay, ph·ªß r∆°m r·∫° gi·ªØ ·∫©m")
                    else:
                        issues.append(f"- ƒê·ªô ·∫©m **{moisture}%** qu√° cao ‚Üí Gi·∫£m t∆∞·ªõi, ki·ªÉm tra tho√°t n∆∞·ªõc")
                
                if not (nitrogen >= 40 and phosphorus >= 30 and potassium >= 150):
                    npk_advice = []
                    if nitrogen < 40:
                        npk_advice.append(f"Nitrogen {nitrogen} mg/kg (thi·∫øu) ‚Üí Ur√™ 46%: 10-15 kg/s√†o")
                    if phosphorus < 30:
                        npk_advice.append(f"Phosphorus {phosphorus} mg/kg (thi·∫øu) ‚Üí L√¢n super 16%: 15-20 kg/s√†o")
                    if potassium < 150:
                        npk_advice.append(f"Potassium {potassium} mg/kg (thi·∫øu) ‚Üí Kali clorua 60%: 5-10 kg/s√†o")
                    issues.append("- NPK thi·∫øu ‚Üí B√≥n ph√¢n:\n  " + "\n  ".join(npk_advice))
                
                if issues:
                    response += "**‚ö†Ô∏è C·∫ßn ƒëi·ªÅu ch·ªânh:**\n" + "\n".join(issues) + "\n\n"
                
                response += "**üå± C√¢y tr·ªìng ph√π h·ª£p hi·ªán t·∫°i:**\n"
                response += "- ü•¨ Rau ƒÉn l√° (c·∫£i, x√† l√°ch): √çt c·∫ßn NPK, sinh tr∆∞·ªüng nhanh\n"
                response += "- ü´ò ƒê·∫≠u c√°c lo·∫°i: T·ª± b·ªï sung ƒë·∫°m, ch·ªãu ƒë∆∞·ª£c ƒëi·ªÅu ki·ªán kh√≥\n\n"
                response += "üí° **L·ªùi khuy√™n:** Sau khi ƒëi·ªÅu ch·ªânh c√°c y·∫øu t·ªë tr√™n, b√°c c√≥ th·ªÉ tr·ªìng nhi·ªÅu lo·∫°i c√¢y c√≥ gi√° tr·ªã kinh t·∫ø cao h∆°n!"
            else:
                response += "**‚ö†Ô∏è ƒê√ÅNH GI√Å: ƒê·∫§T C·∫¶N C·∫¢I THI·ªÜN**\n\n"
                response += "ƒêi·ªÅu ki·ªán hi·ªán t·∫°i ch∆∞a l√Ω t∆∞·ªüng, b√°c n√™n:\n\n"
                response += "**üîß C√°c b∆∞·ªõc c·∫£i thi·ªán:**\n"
                if not (20 <= temp <= 30):
                    response += f"1. ƒêi·ªÅu ch·ªânh nhi·ªát ƒë·ªô (hi·ªán {temp}¬∞C)\n"
                if not (6.0 <= ph <= 7.5):
                    response += f"2. ƒêi·ªÅu ch·ªânh pH (hi·ªán {ph})\n"
                if not (40 <= moisture <= 70):
                    response += f"3. ƒêi·ªÅu ch·ªânh ƒë·ªô ·∫©m (hi·ªán {moisture}%)\n"
                if not (nitrogen >= 40 and phosphorus >= 30 and potassium >= 150):
                    response += f"4. B·ªï sung NPK (hi·ªán N={nitrogen}, P={phosphorus}, K={potassium})\n"
                
                response += "\nüí° **L·ªùi khuy√™n:** B√°c n√™n c·∫£i thi·ªán ƒë·∫•t tr∆∞·ªõc khi tr·ªìng c√¢y c√≥ gi√° tr·ªã cao. Hi·ªán t·∫°i c√≥ th·ªÉ tr·ªìng c√¢y h·ªç ƒë·∫≠u (ƒë·ªó xanh, ƒë·∫≠u ph·ªông) ƒë·ªÉ c·∫£i t·∫°o ƒë·∫•t v√† b·ªï sung ƒë·∫°m t·ª± nhi√™n!"
        
        # If specific metric is focused, only analyze that
        elif metric_focused:
            if metric_focused == 'temperature' and temp > 0:
                response = f"**Nhi·ªát ƒë·ªô ƒë·∫•t: {temp}¬∞C**\n\n"
                if temp < 15:
                    response += f"‚ö†Ô∏è Nhi·ªát ƒë·ªô **{temp}¬∞C** qu√° th·∫•p ƒë√≥ b√°c! C√¢y c√≥ th·ªÉ ng·ª´ng ph√°t tri·ªÉn. B√°c n√™n:\n"
                    response += "- Che ph·ªß b·∫±ng nilon ho·∫∑c l∆∞·ªõi b√≥ng r√¢m\n"
                    response += "- T∆∞·ªõi n∆∞·ªõc v√†o bu·ªïi tr∆∞a khi tr·ªùi ·∫•m\n"
                    response += "- Tr√°nh t∆∞·ªõi n∆∞·ªõc l·∫°nh v√†o s√°ng s·ªõm\n\n"
                    response += "Nhi·ªát ƒë·ªô l√Ω t∆∞·ªüng cho c√¢y tr·ªìng l√† **20-30¬∞C** ƒë√≥ b√°c!"
                elif temp < 20:
                    response += f"Nhi·ªát ƒë·ªô **{temp}¬∞C** h∆°i th·∫•p ƒë√≥ b√°c, c√¢y ph√°t tri·ªÉn ch·∫≠m h∆°n b√¨nh th∆∞·ªùng.\n\n"
                    response += "B√°c c√≥ th·ªÉ t∆∞·ªõi n∆∞·ªõc v√†o bu·ªïi tr∆∞a ƒë·ªÉ gi·ªØ ·∫•m cho ƒë·∫•t, ho·∫∑c che ph·ªß ƒë·ªÉ gi·ªØ nhi·ªát ƒë·ªô ·ªïn ƒë·ªãnh h∆°n nh√©!"
                elif temp > 35:
                    response += f"üî• Nhi·ªát ƒë·ªô **{temp}¬∞C** qu√° cao ƒë√≥ b√°c! C√¢y d·ªÖ b·ªã h√©o v√† stress nhi·ªát. B√°c c·∫ßn:\n"
                    response += "- T∆∞·ªõi n∆∞·ªõc s√°ng s·ªõm v√† chi·ªÅu m√°t\n"
                    response += "- Che b√≥ng m√°t b·∫±ng l∆∞·ªõi 50-70%\n"
                    response += "- Phun s∆∞∆°ng nh·∫π l√™n l√° v√†o tr∆∞a\n\n"
                    response += "Nhi·ªát ƒë·ªô t·ªët nh·∫•t l√† **20-30¬∞C** ƒë√≥ b√°c!"
                elif temp > 30:
                    response += f"Nhi·ªát ƒë·ªô **{temp}¬∞C** h∆°i cao ƒë√≥ b√°c. C√¢y c√≥ th·ªÉ b·ªã stress n·∫øu k√©o d√†i.\n\n"
                    response += "B√°c n√™n t∆∞·ªõi n∆∞·ªõc ƒë·ªÅu ƒë·∫∑n v√† xem x√©t che b·ªõt n·∫Øng v√†o bu·ªïi tr∆∞a ƒë·ªÉ c√¢y kh·ªèe m·∫°nh h∆°n!"
                else:
                    response += f"‚úÖ Nhi·ªát ƒë·ªô **{temp}¬∞C** r·∫•t l√Ω t∆∞·ªüng ƒë√≥ b√°c! ƒê√¢y l√† nhi·ªát ƒë·ªô t·ªët nh·∫•t cho c√¢y ph√°t tri·ªÉn.\n\n"
                    response += "C√¢y ƒëang ·ªü trong ƒëi·ªÅu ki·ªán nhi·ªát ƒë·ªô ho√†n h·∫£o, ti·∫øp t·ª•c duy tr√¨ nh∆∞ v·∫≠y nh√© b√°c!"
                    
            elif metric_focused == 'moisture' and moisture > 0:
                response = f"**ƒê·ªô ·∫©m ƒë·∫•t: {moisture}%**\n\n"
                if moisture < 20:
                    response += f"‚ö†Ô∏è ƒê·ªô ·∫©m **{moisture}%** qu√° kh√¥ ƒë√≥ b√°c! C√¢y ƒëang thi·∫øu n∆∞·ªõc nghi√™m tr·ªçng. B√°c c·∫ßn:\n"
                    response += "- T∆∞·ªõi n∆∞·ªõc ngay l·∫≠p t·ª©c\n"
                    response += "- T∆∞·ªõi t·ª´ t·ª´ ƒë·ªÉ ƒë·∫•t h·∫•p th·ª• t·ªët\n"
                    response += "- Ph·ªß r∆°m r·∫° gi·ªØ ·∫©m\n\n"
                    response += "ƒê·ªô ·∫©m l√Ω t∆∞·ªüng l√† **40-70%** ƒë√≥ b√°c!"
                elif moisture < 30:
                    response += f"ƒê·ªô ·∫©m **{moisture}%** h∆°i kh√¥ ƒë√≥ b√°c. C√¢y c·∫ßn ƒë∆∞·ª£c t∆∞·ªõi th√™m n∆∞·ªõc.\n\n"
                    response += "B√°c n√™n t∆∞·ªõi ƒë·ªÅu ƒë·∫∑n, ƒë·∫∑c bi·ªát v√†o m√πa kh√¥, ƒë·ªÉ c√¢y ph√°t tri·ªÉn t·ªët nh√©!"
                elif moisture > 85:
                    response += f"‚ö†Ô∏è ƒê·ªô ·∫©m **{moisture}%** qu√° cao ƒë√≥ b√°c! Nguy c∆° √∫ng r·ªÖ v√† n·∫•m b·ªánh. B√°c c·∫ßn:\n"
                    response += "- Ng·ª´ng t∆∞·ªõi t·∫°m th·ªùi\n"
                    response += "- Ki·ªÉm tra h·ªá th·ªëng tho√°t n∆∞·ªõc\n"
                    response += "- X·ªõi ƒë·∫•t nh·∫π ƒë·ªÉ tho√°ng kh√≠\n\n"
                    response += "ƒê·ªô ·∫©m t·ªët nh·∫•t l√† **40-70%** ƒë√≥ b√°c!"
                elif moisture > 75:
                    response += f"ƒê·ªô ·∫©m **{moisture}%** h∆°i cao ƒë√≥ b√°c. C√¢y c√≥ th·ªÉ b·ªã √∫ng n∆∞·ªõc.\n\n"
                    response += "B√°c n√™n gi·∫£m l∆∞·ª£ng t∆∞·ªõi v√† ki·ªÉm tra tho√°t n∆∞·ªõc ƒë·ªÉ tr√°nh √∫ng r·ªÖ nh√©!"
                else:
                    response += f"‚úÖ ƒê·ªô ·∫©m **{moisture}%** r·∫•t t·ªët ƒë√≥ b√°c! C√¢y ƒëang ƒë∆∞·ª£c cung c·∫•p n∆∞·ªõc ƒë·∫ßy ƒë·ªß.\n\n"
                    response += "Ti·∫øp t·ª•c duy tr√¨ ƒë·ªô ·∫©m n√†y, c√¢y s·∫Ω ph√°t tri·ªÉn kh·ªèe m·∫°nh!"
                    
            elif metric_focused == 'ph' and ph > 0:
                response = f"**pH ƒë·∫•t: {ph}**\n\n"
                if ph < 5.5:
                    response += f"‚ö†Ô∏è pH **{ph}** qu√° chua ƒë√≥ b√°c! ƒê·∫•t chua l√†m c√¢y h·∫•p th·ª• dinh d∆∞·ª°ng k√©m. B√°c c·∫ßn:\n"
                    response += "- R·∫£i v√¥i b·ªôt 200-300kg/ha\n"
                    response += "- Tr·ªôn ƒë·ªÅu v√†o ƒë·∫•t\n"
                    response += "- ƒê·ª£i 2-3 tu·∫ßn m·ªõi tr·ªìng c√¢y\n\n"
                    response += "pH l√Ω t∆∞·ªüng l√† **6.0-7.5** ƒë√≥ b√°c!"
                elif ph < 6.0:
                    response += f"pH **{ph}** h∆°i chua ƒë√≥ b√°c. C√¢y c√≥ th·ªÉ h·∫•p th·ª• dinh d∆∞·ª°ng kh√¥ng t·ªët.\n\n"
                    response += "B√°c n√™n r·∫£i v√¥i b·ªôt nh·∫π ƒë·ªÉ tƒÉng pH l√™n kho·∫£ng 6.5-7.0 cho t·ªëi ∆∞u nh√©!"
                elif ph > 8.0:
                    response += f"‚ö†Ô∏è pH **{ph}** qu√° ki·ªÅm ƒë√≥ b√°c! ƒê·∫•t ki·ªÅm c≈©ng g√¢y kh√≥ h·∫•p th·ª• dinh d∆∞·ª°ng. B√°c c·∫ßn:\n"
                    response += "- B√≥n ph√¢n l∆∞u hu·ª≥nh\n"
                    response += "- B√≥n ph√¢n chu·ªìng ·ªß hoai\n"
                    response += "- Tr√°nh d√πng v√¥i\n\n"
                    response += "pH t·ªët nh·∫•t l√† **6.0-7.5** ƒë√≥ b√°c!"
                elif ph > 7.5:
                    response += f"pH **{ph}** h∆°i ki·ªÅm ƒë√≥ b√°c. C√¢y c√≥ th·ªÉ thi·∫øu s·∫Øt v√† k·∫Ωm.\n\n"
                    response += "B√°c c√≥ th·ªÉ b√≥n ph√¢n l∆∞u hu·ª≥nh ƒë·ªÉ gi·∫£m pH xu·ªëng m·ªôt ch√∫t nh√©!"
                else:
                    response += f"‚úÖ pH **{ph}** r·∫•t l√Ω t∆∞·ªüng ƒë√≥ b√°c! ƒê√¢y l√† m·ª©c pH t·ªët nh·∫•t cho c√¢y tr·ªìng.\n\n"
                    response += "C√¢y ƒëang h·∫•p th·ª• dinh d∆∞·ª°ng t·ªëi ∆∞u, ti·∫øp t·ª•c duy tr√¨ nh√© b√°c!"
                    
            elif metric_focused in ['nitrogen', 'phosphorus', 'potassium'] or 'NPK' in message:
                response = f"**Ch·ªâ s·ªë NPK: N={nitrogen}, P={phosphorus}, K={potassium}**\n\n"
                issues = []
                
                if nitrogen < 30:
                    issues.append(f"‚ö†Ô∏è **Nitrogen {nitrogen} mg/kg** - Qu√° th·∫•p! C√¢y s·∫Ω l√° v√†ng, ph√°t tri·ªÉn k√©m.")
                elif nitrogen < 40:
                    issues.append(f"**Nitrogen {nitrogen} mg/kg** - H∆°i th·∫•p, c√¢y c·∫ßn th√™m ƒë·∫°m.")
                else:
                    issues.append(f"‚úÖ **Nitrogen {nitrogen} mg/kg** - T·ªët!")
                    
                if phosphorus < 20:
                    issues.append(f"‚ö†Ô∏è **Phosphorus {phosphorus} mg/kg** - Qu√° th·∫•p! R·ªÖ ph√°t tri·ªÉn k√©m, kh√≥ ra hoa.")
                elif phosphorus < 30:
                    issues.append(f"**Phosphorus {phosphorus} mg/kg** - H∆°i th·∫•p, c√¢y c·∫ßn th√™m l√¢n.")
                else:
                    issues.append(f"‚úÖ **Phosphorus {phosphorus} mg/kg** - T·ªët!")
                    
                if potassium < 100:
                    issues.append(f"‚ö†Ô∏è **Potassium {potassium} mg/kg** - Qu√° th·∫•p! C√¢y k√©m ch·ªëng ch·ªãu s√¢u b·ªánh.")
                elif potassium < 150:
                    issues.append(f"**Potassium {potassium} mg/kg** - H∆°i th·∫•p, c√¢y c·∫ßn th√™m kali.")
                else:
                    issues.append(f"‚úÖ **Potassium {potassium} mg/kg** - T·ªët!")
                
                response += "\n".join(issues) + "\n\n"
                
                if nitrogen < 40 or phosphorus < 30 or potassium < 150:
                    response += "**Khuy·∫øn ngh·ªã b√≥n ph√¢n:**\n"
                    if nitrogen < 40:
                        response += "- ƒê·∫°m ur√™ 46%: 10-15 kg/s√†o\n"
                    if phosphorus < 30:
                        response += "- L√¢n super 16%: 15-20 kg/s√†o\n"
                    if potassium < 150:
                        response += "- Kali clorua 60%: 5-10 kg/s√†o\n"
                    response += "\nB√≥n c√°ch g·ªëc 10-15cm, sau ƒë√≥ t∆∞·ªõi n∆∞·ªõc nh√© b√°c!"
                else:
                    response += "Ch·ªâ s·ªë NPK r·∫•t t·ªët! C√¢y ƒëang ƒë∆∞·ª£c dinh d∆∞·ª°ng ƒë·∫ßy ƒë·ªß, ti·∫øp t·ª•c duy tr√¨ nh√© b√°c!"
                    
            elif metric_focused == 'humidity' and humidity > 0:
                response = f"**ƒê·ªô ·∫©m kh√¥ng kh√≠: {humidity}%**\n\n"
                if humidity > 90:
                    response += f"‚ö†Ô∏è ƒê·ªô ·∫©m **{humidity}%** qu√° cao ƒë√≥ b√°c! Nguy c∆° n·∫•m b·ªánh r·∫•t l·ªõn. B√°c c·∫ßn:\n"
                    response += "- T·ªâa b·ªõt l√° d√†y ƒë·∫∑c\n"
                    response += "- TƒÉng kho·∫£ng c√°ch c√¢y\n"
                    response += "- Phun thu·ªëc ph√≤ng n·∫•m\n\n"
                    response += "ƒê·ªô ·∫©m t·ªët l√† **60-80%** ƒë√≥ b√°c!"
                elif humidity > 85:
                    response += f"ƒê·ªô ·∫©m **{humidity}%** h∆°i cao ƒë√≥ b√°c. D·ªÖ sinh n·∫•m b·ªánh.\n\n"
                    response += "B√°c n√™n t·ªâa b·ªõt l√° v√† th√¥ng tho√°ng v∆∞·ªùn ƒë·ªÉ gi·∫£m ƒë·ªô ·∫©m nh√©!"
                elif humidity < 40:
                    response += f"ƒê·ªô ·∫©m **{humidity}%** h∆°i kh√¥ ƒë√≥ b√°c. C√¢y c√≥ th·ªÉ m·∫•t n∆∞·ªõc qua l√°.\n\n"
                    response += "B√°c c√≥ th·ªÉ phun s∆∞∆°ng nh·∫π ho·∫∑c t∆∞·ªõi ƒë·ªÅu ƒë·ªÉ tƒÉng ƒë·ªô ·∫©m kh√¥ng kh√≠!"
                else:
                    response += f"‚úÖ ƒê·ªô ·∫©m **{humidity}%** r·∫•t t·ªët ƒë√≥ b√°c! C√¢y ƒëang ·ªü ƒëi·ªÅu ki·ªán l√Ω t∆∞·ªüng.\n\n"
                    response += "Ti·∫øp t·ª•c duy tr√¨, c√¢y s·∫Ω ph√°t tri·ªÉn kh·ªèe m·∫°nh!"
        elif is_crop_recommendation:
            # Crop recommendation based on current conditions
            response = "D·ª±a v√†o ƒëi·ªÅu ki·ªán ƒë·∫•t c·ªßa b√°c, ch√°u xin t∆∞ v·∫•n m·ªôt s·ªë lo·∫°i c√¢y ph√π h·ª£p:\n\n"
            
            suitable_crops = []
            reasons = []
            
            # Analyze conditions for crop recommendation
            temp_suitable = 20 <= temp <= 30
            moisture_suitable = 40 <= moisture <= 70
            ph_suitable = 6.0 <= ph <= 7.5
            npk_good = nitrogen >= 40 and phosphorus >= 30 and potassium >= 150
            
            if temp_suitable and ph_suitable:
                if npk_good:
                    suitable_crops.append("üçÖ **C√† chua**")
                    reasons.append("- Nhi·ªát ƒë·ªô, pH v√† NPK ƒë·ªÅu l√Ω t∆∞·ªüng")
                    reasons.append("- C·∫ßn t∆∞·ªõi ƒë·ªÅu, ƒë·ªô ·∫©m 50-70%")
                    reasons.append("- Thu ho·∫°ch sau 90-120 ng√†y")
                    
                    suitable_crops.append("ü•¨ **Rau xanh (x√† l√°ch, c·∫£i)**")
                    reasons.append("- ƒêi·ªÅu ki·ªán ƒë·∫•t r·∫•t ph√π h·ª£p")
                    reasons.append("- Sinh tr∆∞·ªüng nhanh 30-45 ng√†y")
                    reasons.append("- C·∫ßn √≠t c√¥ng chƒÉm s√≥c")
                else:
                    suitable_crops.append("ü•¨ **Rau ƒÉn l√° (c·∫£i, x√† l√°ch)**")
                    reasons.append("- √çt c·∫ßn NPK, ph√π h·ª£p v·ªõi ƒë·∫•t hi·ªán t·∫°i")
                    reasons.append("- Sinh tr∆∞·ªüng nhanh 30-45 ng√†y")
                    
                if potassium >= 150:
                    suitable_crops.append("ü•í **D∆∞a leo, d∆∞a chu·ªôt**")
                    reasons.append("- Kali cao gi√∫p qu·∫£ to, ng·ªçt")
                    reasons.append("- Nhi·ªát ƒë·ªô v√† pH th√≠ch h·ª£p")
                    reasons.append("- Thu ho·∫°ch sau 50-60 ng√†y")
            
            if ph >= 6.5 and nitrogen >= 40:
                suitable_crops.append("üå∂Ô∏è **·ªöt, ti√™u**")
                reasons.append("- pH h∆°i cao ph√π h·ª£p v·ªõi ·ªõt")
                reasons.append("- Nitrogen ƒë·ªß cho l√° xanh t·ªët")
                reasons.append("- Thu ho·∫°ch nhi·ªÅu ƒë·ª£t")
            
            if temp >= 25 and moisture >= 50:
                suitable_crops.append("ü´ò **ƒê·∫≠u c√°c lo·∫°i**")
                reasons.append("- Nhi·ªát ·∫©m cao ph√π h·ª£p")
                reasons.append("- T·ª± b·ªï sung ƒë·∫°m cho ƒë·∫•t")
                reasons.append("- Thu ho·∫°ch sau 60-70 ng√†y")
            
            if suitable_crops:
                response += f"**‚úÖ Top {len(suitable_crops)} c√¢y tr·ªìng ph√π h·ª£p:**\n\n"
                for i, crop in enumerate(suitable_crops[:3], 1):  # Top 3
                    response += f"{i}. {crop}\n"
                
                response += f"\n**üìä ƒêi·ªÅu ki·ªán hi·ªán t·∫°i:**\n"
                response += f"- Nhi·ªát ƒë·ªô: **{temp}¬∞C** {'‚úÖ' if temp_suitable else '‚ö†Ô∏è'}\n"
                response += f"- pH: **{ph}** {'‚úÖ' if ph_suitable else '‚ö†Ô∏è'}\n"
                response += f"- NPK: N={nitrogen}, P={phosphorus}, K={potassium} {'‚úÖ' if npk_good else '‚ö†Ô∏è'}\n\n"
                
                response += "**üí° L∆∞u √Ω:**\n"
                response += "- Tr·ªìng v√†o ƒë·∫ßu m√πa m∆∞a ho·∫∑c ƒë·∫ßu m√πa kh√¥\n"
                response += "- Chu·∫©n b·ªã ƒë·∫•t k·ªπ tr∆∞·ªõc khi gieo tr·ªìng\n"
                response += "- B√≥n ph√¢n b·ªï sung theo t·ª´ng giai ƒëo·∫°n\n\n"
                response += "B√°c c√≥ th·ªÉ h·ªèi th√™m v·ªÅ c√°ch tr·ªìng t·ª´ng lo·∫°i c√¢y nh√©! üåæ"
            else:
                response += "V·ªõi ƒëi·ªÅu ki·ªán hi·ªán t·∫°i, b√°c n√™n:\n"
                if not temp_suitable:
                    response += "- ƒêi·ªÅu ch·ªânh nhi·ªát ƒë·ªô (ƒëang {temp}¬∞C)\n"
                if not ph_suitable:
                    response += "- ƒêi·ªÅu ch·ªânh pH (ƒëang {ph})\n"
                if not npk_good:
                    response += "- B√≥n th√™m ph√¢n NPK\n"
                response += "\nSau khi ƒëi·ªÅu ch·ªânh, b√°c c√≥ th·ªÉ tr·ªìng nhi·ªÅu lo·∫°i c√¢y h∆°n ƒë√≥!"
                
        elif is_general_chat:
            # General chat response - natural conversation
            response = "ƒê·ªÉ ch√°u xem t√¨nh h√¨nh v∆∞·ªùn nh√† b√°c nh√©!\n\n"
            
            issues = []
            good_points = []
            
            if 20 <= temp <= 30:
                good_points.append(f"‚úÖ Nhi·ªát ƒë·ªô **{temp}¬∞C** r·∫•t l√Ω t∆∞·ªüng")
            elif temp > 0:
                issues.append(f"‚ö†Ô∏è Nhi·ªát ƒë·ªô **{temp}¬∞C** c·∫ßn ch√∫ √Ω")
            
            if 40 <= moisture <= 70:
                good_points.append(f"‚úÖ ƒê·ªô ·∫©m ƒë·∫•t **{moisture}%** t·ªët")
            elif moisture > 0:
                issues.append(f"‚ö†Ô∏è ƒê·ªô ·∫©m **{moisture}%** c·∫ßn ƒëi·ªÅu ch·ªânh")
            
            if 6.0 <= ph <= 7.5:
                good_points.append(f"‚úÖ pH **{ph}** l√Ω t∆∞·ªüng")
            elif ph > 0:
                issues.append(f"‚ö†Ô∏è pH **{ph}** c·∫ßn ƒëi·ªÅu ch·ªânh")
            
            if nitrogen >= 40 and phosphorus >= 30 and potassium >= 150:
                good_points.append(f"‚úÖ NPK ƒë·∫ßy ƒë·ªß (N={nitrogen}, P={phosphorus}, K={potassium})")
            else:
                issues.append(f"‚ö†Ô∏è NPK c·∫ßn b·ªï sung (N={nitrogen}, P={phosphorus}, K={potassium})")
            
            if good_points:
                response += "**ƒêi·ªÉm t·ªët:**\n" + "\n".join(good_points) + "\n\n"
            
            if issues:
                response += "**C·∫ßn l∆∞u √Ω:**\n" + "\n".join(issues) + "\n\n"
            
            if len(good_points) >= 3:
                response += "Nh√¨n chung v∆∞·ªùn b√°c ƒëang r·∫•t kh·ªèe! Ti·∫øp t·ª•c duy tr√¨ nh∆∞ v·∫≠y nh√©. "
                response += "B√°c c√≥ th·ªÉ h·ªèi ch√°u v·ªÅ c√¢y tr·ªìng ph√π h·ª£p ho·∫∑c c√°ch chƒÉm s√≥c c·ª• th·ªÉ! üåæ"
            elif len(issues) >= 2:
                response += "V∆∞·ªùn b√°c c·∫ßn ƒëi·ªÅu ch·ªânh m·ªôt ch√∫t. B√°c click v√†o t·ª´ng ch·ªâ s·ªë ƒë·ªÉ ch√°u t∆∞ v·∫•n chi ti·∫øt nh√©!"
            else:
                response += "V∆∞·ªùn b√°c kh√° ·ªïn r·ªìi ƒë√≥! Click v√†o t·ª´ng ch·ªâ s·ªë ƒë·ªÉ xem ph√¢n t√≠ch chi ti·∫øt nh√© b√°c! üåæ"
        
        else:
            # General analysis if no specific metric detected
            response = "Ch√†o b√°c n√¥ng d√¢n! ƒê·ªÉ ch√°u xem t·ªïng quan v∆∞·ªùn nh√† m√¨nh nh√©.\n\n"
            
            if temp > 0:
                status = "t·ªët" if 20 <= temp <= 30 else "c·∫ßn ch√∫ √Ω"
                response += f"üå°Ô∏è Nhi·ªát ƒë·ªô ƒë·∫•t: **{temp}¬∞C** ({status})\n"
            
            if moisture > 0:
                status = "t·ªët" if 40 <= moisture <= 70 else "c·∫ßn ƒëi·ªÅu ch·ªânh"
                response += f"üíß ƒê·ªô ·∫©m ƒë·∫•t: **{moisture}%** ({status})\n"
            
            if ph > 0:
                status = "l√Ω t∆∞·ªüng" if 6.0 <= ph <= 7.5 else "c·∫ßn ƒëi·ªÅu ch·ªânh"
                response += f"‚öóÔ∏è pH: **{ph}** ({status})\n"
            
            response += f"üå± NPK: N={nitrogen}, P={phosphorus}, K={potassium}\n\n"
            response += "B√°c c√≥ th·ªÉ:\n"
            response += "- Click v√†o t·ª´ng ch·ªâ s·ªë ƒë·ªÉ xem ph√¢n t√≠ch chi ti·∫øt\n"
            response += "- H·ªèi ch√°u v·ªÅ c√¢y tr·ªìng ph√π h·ª£p\n"
            response += "- H·ªèi ch√°u v·ªÅ c√°ch chƒÉm s√≥c c·ª• th·ªÉ üåæ"
        
        return jsonify({"response": response}), 200
        
    except Exception as e:
        logger.error(f"‚ùå AI chat error: {e}", exc_info=True)
        return jsonify({"error": str(e)}), 500


@flask_app.route("/api/ai/analyze", methods=["POST"])
def flask_ai_analyze():
    """
    Flask wrapper for AI analysis - analyze single data point or aggregated data
    """
    try:
        data = request.get_json(silent=True) or {}
        
        # Validate required fields
        required = ['soil_temperature', 'soil_moisture', 'conductivity', 'ph', 
                   'nitrogen', 'phosphorus', 'potassium', 'salt',
                   'air_temperature', 'air_humidity', 'is_raining']
        
        missing = [f for f in required if f not in data]
        if missing:
            return jsonify({"detail": f"Missing fields: {', '.join(missing)}"}), 400
        
        # ‚úÖ CALL ML MODELS DIRECTLY using analyze_soil() function
        from ai_service.schemas import SoilDataInput
        
        # Create input object
        soil_input = SoilDataInput(
            soil_temperature=float(data['soil_temperature']),
            soil_moisture=float(data['soil_moisture']),
            ph=float(data['ph']),
            conductivity=int(data['conductivity']),
            nitrogen=int(data['nitrogen']),
            phosphorus=int(data['phosphorus']),
            potassium=int(data['potassium']),
            salt=int(data['salt']),
            air_temperature=float(data['air_temperature']),
            air_humidity=float(data['air_humidity']),
            is_raining=bool(data['is_raining']),
            mode=data.get('mode', 'discovery'),
            selected_crop=data.get('selected_crop')
        )
        
        # Load models if not loaded
        models = get_model_registry()
        if not models.validate_loaded():
            logger.info("üîÑ Loading ML models...")
            models.load_all()
        
        # Call ML inference
        result = analyze_soil(soil_input, models)
        
        # Convert to dict for JSON response
        return jsonify(result.dict()), 200
        
    except Exception as e:
        logger.error(f"‚ùå AI analyze error: {e}", exc_info=True)
        return jsonify({"detail": str(e)}), 500


@flask_app.route("/api/ai/analyze-daily", methods=["POST"])
def flask_analyze_daily():
    """
    Flask wrapper for AI daily analysis - simplified version calling /api/analyze-date
    """
    try:
        data = request.get_json(silent=True) or {}
        date_str = data.get("date")
        
        if not date_str:
            return jsonify({"detail": "date is required (YYYY-MM-DD)"}), 400
        
        # Call the existing /api/analyze-date endpoint internally
        # This returns the same data structure
        return analyze_date()
        
    except Exception as e:
        logger.error(f"‚ùå Daily aggregation error: {e}", exc_info=True)
        return jsonify({"detail": str(e)}), 500


@flask_app.route("/api/analyze-date", methods=["POST"])
def analyze_date():
    """
    Analyze soil data for a specific date - aggregates daily readings and calls AI
    
    Request: {"date": "2025-10-27"}
    Response: {
        "status": "success",
        "date": "2025-10-27",
        "sample_count": 48,
        "aggregated_data": {...},
        "ai_analysis": {...}
    }
    """
    try:
        data = request.get_json(silent=True) or {}
        date_str = data.get("date")
        
        if not date_str:
            return jsonify({"status": "error", "message": "date is required (YYYY-MM-DD)"}), 400
        
        # Validate date format
        try:
            datetime.strptime(date_str, "%Y-%m-%d")
        except ValueError:
            return jsonify({"status": "error", "message": "Invalid date format. Use YYYY-MM-DD"}), 400
        
        # Query DB: HYBRID aggregation (AVG + MEDIAN + MAJORITY)
        with get_db_conn() as conn:
            with conn.cursor() as cur:
                query = """
                SELECT
                    COUNT(*) as sample_count,
                    MIN(measured_at_vn) as first_reading,
                    MAX(measured_at_vn) as last_reading,
                    
                    AVG(soil_temperature_c) as soil_temperature,
                    AVG(soil_moisture_pct) as soil_moisture,
                    AVG(ph_value) as ph,
                    AVG(nitrogen_mg_kg) as nitrogen,
                    AVG(phosphorus_mg_kg) as phosphorus,
                    AVG(potassium_mg_kg) as potassium,
                    AVG(air_temperature_c) as air_temperature,
                    AVG(air_humidity_pct) as air_humidity,
                    
                    PERCENTILE_CONT(0.5) WITHIN GROUP (ORDER BY conductivity_us_cm) as conductivity,
                    PERCENTILE_CONT(0.5) WITHIN GROUP (ORDER BY salt_mg_l) as salt,
                    
                    (SUM(CASE WHEN is_raining THEN 1 ELSE 0 END)::float / COUNT(*)) > 0.5 as is_raining,
                    
                    MIN(soil_temperature_c) as min_soil_temp,
                    MAX(soil_temperature_c) as max_soil_temp,
                    MIN(soil_moisture_pct) as min_moisture,
                    MAX(soil_moisture_pct) as max_moisture,
                    STDDEV(soil_moisture_pct) as moisture_variance
                    
                FROM sensor_readings
                WHERE DATE(measured_at_vn AT TIME ZONE 'Asia/Ho_Chi_Minh') = %s
                """
                
                cur.execute(query, (date_str,))
                result = cur.fetchone()
                
                if not result or result[0] == 0:
                    return jsonify({
                        "status": "error",
                        "message": f"No sensor data found for date {date_str}"
                    }), 404
                
                # Prepare aggregated data
                aggregated_data = {
                    "sample_count": int(result[0]),
                    "time_range": {
                        "first": result[1].strftime('%Y-%m-%d %H:%M:%S') if result[1] else None,
                        "last": result[2].strftime('%Y-%m-%d %H:%M:%S') if result[2] else None
                    },
                    "averages": {
                        "soil_temperature": float(result[3]) if result[3] is not None else 0,
                        "soil_moisture": float(result[4]) if result[4] is not None else 0,
                        "ph": float(result[5]) if result[5] is not None else 0,
                        "nitrogen": float(result[6]) if result[6] is not None else 0,
                        "phosphorus": float(result[7]) if result[7] is not None else 0,
                        "potassium": float(result[8]) if result[8] is not None else 0,
                        "air_temperature": float(result[9]) if result[9] is not None else 0,
                        "air_humidity": float(result[10]) if result[10] is not None else 0,
                        "conductivity": float(result[11]) if result[11] is not None else 0,
                        "salt": float(result[12]) if result[12] is not None else 0,
                        "is_raining": bool(result[13])
                    },
                    "ranges": {
                        "soil_temp_min": float(result[14]) if result[14] is not None else 0,
                        "soil_temp_max": float(result[15]) if result[15] is not None else 0,
                        "moisture_min": float(result[16]) if result[16] is not None else 0,
                        "moisture_max": float(result[17]) if result[17] is not None else 0,
                        "moisture_variance": float(result[18]) if result[18] is not None else 0
                    }
                }
        
        # Call Flask AI analysis endpoint (WITH ML MODELS)
        ai_service_url = "http://localhost:8080/api/ai/analyze"
        
        ai_payload = {
            "soil_temperature": aggregated_data['averages']['soil_temperature'],
            "soil_moisture": aggregated_data['averages']['soil_moisture'],
            "conductivity": int(aggregated_data['averages']['conductivity']),
            "ph": aggregated_data['averages']['ph'],
            "nitrogen": int(aggregated_data['averages']['nitrogen']),
            "phosphorus": int(aggregated_data['averages']['phosphorus']),
            "potassium": int(aggregated_data['averages']['potassium']),
            "salt": int(aggregated_data['averages']['salt']),
            "air_temperature": aggregated_data['averages']['air_temperature'],
            "air_humidity": aggregated_data['averages']['air_humidity'],
            "is_raining": aggregated_data['averages']['is_raining'],
            "mode": "discovery"
        }
        
        ai_result = None
        try:
            import urllib.request
            import json as json_lib
            
            req = urllib.request.Request(
                ai_service_url,
                data=json_lib.dumps(ai_payload).encode("utf-8"),
                headers={"Content-Type": "application/json"},
                method="POST"
            )
            
            with urllib.request.urlopen(req, timeout=15) as resp:
                ai_result = json_lib.loads(resp.read().decode("utf-8"))
                
        except Exception as e:
            # AI service error - still return data but mark AI as failed
            ai_result = {
                "error": str(e),
                "status": "AI service unavailable"
            }
        
        # üíæ SAVE TO daily_insights TABLE (simplified version for Flask)
        record_id = None
        try:
            if ai_result and isinstance(ai_result, dict):
                logger.info(f"üíæ Saving daily insight to database...")
                
                with get_db_conn() as conn:
                    with conn.cursor() as cur:
                        # Simplified INSERT (only basic fields, no ML predictions)
                        insert_query = """
                        INSERT INTO daily_insights (
                            date_vn, total_readings,
                            soil_temperature_avg, soil_moisture_avg, conductivity_avg, ph_avg,
                            nitrogen_avg, phosphorus_avg, potassium_avg, salt_avg,
                            air_temperature_avg, air_humidity_avg, is_raining_majority,
                            recommended_crop, crop_confidence, 
                            soil_health_score, soil_health_rating,
                            has_anomaly, anomaly_score,
                            summary_status, summary_text,
                            ai_analysis_json, recommendations_json
                        )
                        VALUES (%s, %s, %s, %s, %s, %s, %s, %s, %s, %s, %s, %s, %s, %s, %s, %s, %s, %s, %s, %s, %s, %s, %s)
                        RETURNING id
                        """
                        
                        # Extract values from dict-based ai_result
                        crop_rec = ai_result.get('crop_recommendation', {})
                        soil_health = ai_result.get('soil_health', {})
                        anomaly = ai_result.get('anomaly_detection', {})
                        
                        recommended_crop = crop_rec.get('best_crop', 'Unknown')
                        crop_confidence = crop_rec.get('confidence', 0)
                        soil_score = soil_health.get('score', 0)
                        soil_rating = soil_health.get('rating', 'Unknown')
                        has_anomaly = anomaly.get('is_anomaly', False)
                        anomaly_score = anomaly.get('score', 0)
                        
                        # Determine summary status
                        if has_anomaly:
                            summary_status = "ALERT"
                        elif soil_score >= 80:
                            summary_status = "EXCELLENT"
                        elif soil_score >= 60:
                            summary_status = "GOOD"
                        else:
                            summary_status = "NEEDS_ATTENTION"
                        
                        summary_text = f"Soil Health: {soil_rating} ({soil_score:.1f}/100). Recommended crop: {recommended_crop}. {'ANOMALY DETECTED!' if has_anomaly else 'Normal conditions.'}"
                        
                        # Generate recommendations JSON
                        recommendations = []
                        if has_anomaly:
                            recommendations.append({
                                "priority": "HIGH",
                                "message": f"‚ö†Ô∏è Ph√°t hi·ªán b·∫•t th∆∞·ªùng trong d·ªØ li·ªáu ƒë·∫•t (score: {anomaly_score:.1f}). Ki·ªÉm tra ngay!"
                            })
                        
                        if soil_score < 50:
                            recommendations.append({
                                "priority": "HIGH",
                                "message": f"üå± Ch·∫•t l∆∞·ª£ng ƒë·∫•t k√©m ({soil_rating}). C·∫ßn c·∫£i t·∫°o ƒë·∫•t v√† b√≥n ph√¢n."
                            })
                        elif soil_score < 70:
                            recommendations.append({
                                "priority": "MEDIUM",
                                "message": f"üåø Ch·∫•t l∆∞·ª£ng ƒë·∫•t trung b√¨nh. B√≥n ph√¢n b·ªï sung NPK ƒë·ªãnh k·ª≥."
                            })
                        else:
                            recommendations.append({
                                "priority": "LOW",
                                "message": f"‚úÖ Ch·∫•t l∆∞·ª£ng ƒë·∫•t t·ªët! Duy tr√¨ ch·∫ø ƒë·ªô chƒÉm s√≥c hi·ªán t·∫°i."
                            })
                        
                        if recommended_crop != 'Unknown':
                            recommendations.append({
                                "priority": "INFO",
                                "message": f"üåæ G·ª£i √Ω c√¢y tr·ªìng ph√π h·ª£p: {recommended_crop} (ƒë·ªô tin c·∫≠y: {crop_confidence}%)"
                            })
                        
                        import json
                        recommendations_json = json.dumps(recommendations, ensure_ascii=False)
                        
                        cur.execute(insert_query, (
                            date_str,
                            aggregated_data['sample_count'],
                            aggregated_data['averages']['soil_temperature'],
                            aggregated_data['averages']['soil_moisture'],
                            aggregated_data['averages']['conductivity'],
                            aggregated_data['averages']['ph'],
                            aggregated_data['averages']['nitrogen'],
                            aggregated_data['averages']['phosphorus'],
                            aggregated_data['averages']['potassium'],
                            aggregated_data['averages']['salt'],
                            aggregated_data['averages']['air_temperature'],
                            aggregated_data['averages']['air_humidity'],
                            aggregated_data['averages']['is_raining'],
                            recommended_crop,
                            crop_confidence,
                            soil_score,
                            soil_rating,
                            has_anomaly,
                            anomaly_score,
                            summary_status,
                            summary_text,
                            json.dumps(ai_result, ensure_ascii=False),
                            recommendations_json
                        ))
                        
                        result = cur.fetchone()
                        record_id = result[0] if result else None
                        conn.commit()
                        
                logger.info(f"‚úÖ Saved to daily_insights (ID: {record_id})")
        except Exception as save_error:
            logger.error(f"‚ö†Ô∏è Failed to save daily insight: {save_error}", exc_info=True)
            # Continue even if save fails
        
        return jsonify({
            "status": "success",
            "date": date_str,
            "aggregated_data": aggregated_data,
            "ai_analysis": ai_result,
            "saved_to_db": record_id is not None,
            "record_id": record_id
        }), 200
        
    except Exception as e:
        print(f"‚ùå Analyze-date error: {e}")
        return jsonify({"status": "error", "message": str(e)}), 500


@flask_app.route("/api/ai/analyze-display-only", methods=["POST"])
def analyze_display_only():
    """
    N√∫t "Analyze Daily": CH·ªà HI·ªÇN TH·ªä, KH√îNG L∆ØU DB
    
    Request: {"date": "2025-10-27"}
    Response: same as /api/analyze-date but without saving
    """
    try:
        data = request.get_json(silent=True) or {}
        date_str = data.get("date")
        
        if not date_str:
            return jsonify({"status": "error", "message": "date is required (YYYY-MM-DD)"}), 400
        
        # Query + aggregate data (same as /api/analyze-date)
        with get_db_conn() as conn:
            with conn.cursor() as cur:
                query = """
                SELECT
                    COUNT(*) as sample_count,
                    MIN(measured_at_vn) as first_reading,
                    MAX(measured_at_vn) as last_reading,
                    AVG(soil_temperature_c) as soil_temperature,
                    AVG(soil_moisture_pct) as soil_moisture,
                    AVG(ph_value) as ph,
                    AVG(nitrogen_mg_kg) as nitrogen,
                    AVG(phosphorus_mg_kg) as phosphorus,
                    AVG(potassium_mg_kg) as potassium,
                    AVG(air_temperature_c) as air_temperature,
                    AVG(air_humidity_pct) as air_humidity,
                    PERCENTILE_CONT(0.5) WITHIN GROUP (ORDER BY conductivity_us_cm) as conductivity,
                    PERCENTILE_CONT(0.5) WITHIN GROUP (ORDER BY salt_mg_l) as salt,
                    (SUM(CASE WHEN is_raining THEN 1 ELSE 0 END)::float / COUNT(*)) > 0.5 as is_raining
                FROM sensor_readings
                WHERE DATE(measured_at_vn AT TIME ZONE 'Asia/Ho_Chi_Minh') = %s
                """
                
                cur.execute(query, (date_str,))
                result = cur.fetchone()
                
                if not result or result[0] == 0:
                    return jsonify({
                        "status": "error",
                        "message": f"No sensor data found for date {date_str}"
                    }), 404
                
                aggregated_data = {
                    "sample_count": int(result[0]),
                    "time_range": {
                        "first": result[1].strftime('%Y-%m-%d %H:%M:%S') if result[1] else None,
                        "last": result[2].strftime('%Y-%m-%d %H:%M:%S') if result[2] else None
                    },
                    "averages": {
                        "soil_temperature": float(result[3]) if result[3] is not None else 0,
                        "soil_moisture": float(result[4]) if result[4] is not None else 0,
                        "ph": float(result[5]) if result[5] is not None else 0,
                        "nitrogen": float(result[6]) if result[6] is not None else 0,
                        "phosphorus": float(result[7]) if result[7] is not None else 0,
                        "potassium": float(result[8]) if result[8] is not None else 0,
                        "air_temperature": float(result[9]) if result[9] is not None else 0,
                        "air_humidity": float(result[10]) if result[10] is not None else 0,
                        "conductivity": float(result[11]) if result[11] is not None else 0,
                        "salt": float(result[12]) if result[12] is not None else 0,
                        "is_raining": bool(result[13])
                    }
                }
        
        # Call Flask AI analysis endpoint (WITH ML MODELS)
        ai_service_url = "http://localhost:8080/api/ai/analyze"
        ai_payload = {
            "soil_temperature": aggregated_data['averages']['soil_temperature'],
            "soil_moisture": aggregated_data['averages']['soil_moisture'],
            "conductivity": int(aggregated_data['averages']['conductivity']),
            "ph": aggregated_data['averages']['ph'],
            "nitrogen": int(aggregated_data['averages']['nitrogen']),
            "phosphorus": int(aggregated_data['averages']['phosphorus']),
            "potassium": int(aggregated_data['averages']['potassium']),
            "salt": int(aggregated_data['averages']['salt']),
            "air_temperature": aggregated_data['averages']['air_temperature'],
            "air_humidity": aggregated_data['averages']['air_humidity'],
            "is_raining": aggregated_data['averages']['is_raining'],
            "mode": "discovery"
        }
        
        ai_result = None
        try:
            import urllib.request
            import json as json_lib
            
            req = urllib.request.Request(
                ai_service_url,
                data=json_lib.dumps(ai_payload).encode("utf-8"),
                headers={"Content-Type": "application/json"},
                method="POST"
            )
            
            with urllib.request.urlopen(req, timeout=15) as resp:
                ai_result = json_lib.loads(resp.read().decode("utf-8"))
                
        except Exception as e:
            ai_result = {"error": str(e), "status": "AI service unavailable"}
        
        # ‚úÖ KH√îNG L∆ØU DB - CH·ªà HI·ªÇN TH·ªä
        logger.info(f"üìä Display-only analysis for {date_str} (not saved)")
        
        return jsonify({
            "status": "success",
            "date": date_str,
            "aggregated_data": aggregated_data,
            "ai_analysis": ai_result,
            "saved_to_db": False,
            "display_only": True
        }), 200
        
    except Exception as e:
        logger.error(f"‚ùå Display-only analysis error: {e}", exc_info=True)
        return jsonify({"status": "error", "message": str(e)}), 500


@flask_app.route("/api/ai/analyze-and-save", methods=["POST"])
def analyze_and_save():
    """
    N√∫t "Analyze": PH√ÇN T√çCH M·∫™U M·ªöI NH·∫§T + L∆ØU V√ÄO ai_analysis + PUSH BLOCKCHAIN
    
    Request: {} (no params needed - always uses latest sample)
    Response: analysis result + DB record ID + blockchain TX
    """
    try:
        # Get LATEST sensor reading (not aggregated, just the newest sample)
        with get_db_conn() as conn:
            with conn.cursor() as cur:
                query = """
                SELECT
                    id,
                    measured_at_vn,
                    soil_temperature_c,
                    soil_moisture_pct,
                    ph_value,
                    nitrogen_mg_kg,
                    phosphorus_mg_kg,
                    potassium_mg_kg,
                    air_temperature_c,
                    air_humidity_pct,
                    conductivity_us_cm,
                    salt_mg_l,
                    is_raining
                FROM sensor_readings
                ORDER BY created_at_vn DESC
                LIMIT 1
                """
                
                cur.execute(query)
                result = cur.fetchone()
                
                if not result:
                    return jsonify({
                        "status": "error",
                        "message": "No sensor data available"
                    }), 404
                
                sensor_reading_id = result[0]
                measured_at = result[1]
                
                latest_data = {
                    "sample_count": 1,
                    "measured_at": measured_at.strftime('%Y-%m-%d %H:%M:%S') if measured_at else None,
                    "soil_temperature": float(result[2]) if result[2] is not None else 0,
                    "soil_moisture": float(result[3]) if result[3] is not None else 0,
                    "ph": float(result[4]) if result[4] is not None else 0,
                    "nitrogen": float(result[5]) if result[5] is not None else 0,
                    "phosphorus": float(result[6]) if result[6] is not None else 0,
                    "potassium": float(result[7]) if result[7] is not None else 0,
                    "air_temperature": float(result[8]) if result[8] is not None else 0,
                    "air_humidity": float(result[9]) if result[9] is not None else 0,
                    "conductivity": float(result[10]) if result[10] is not None else 0,
                    "salt": float(result[11]) if result[11] is not None else 0,
                    "is_raining": bool(result[12])
                }
        
        # Call Flask AI analysis endpoint (WITH ML MODELS)
        ai_service_url = "http://localhost:8080/api/ai/analyze"
        ai_payload = {
            "soil_temperature": latest_data['soil_temperature'],
            "soil_moisture": latest_data['soil_moisture'],
            "conductivity": int(latest_data['conductivity']),
            "ph": latest_data['ph'],
            "nitrogen": int(latest_data['nitrogen']),
            "phosphorus": int(latest_data['phosphorus']),
            "potassium": int(latest_data['potassium']),
            "salt": int(latest_data['salt']),
            "air_temperature": latest_data['air_temperature'],
            "air_humidity": latest_data['air_humidity'],
            "is_raining": latest_data['is_raining'],
            "mode": "discovery"
        }
        
        ai_result = None
        try:
            import urllib.request
            import json as json_lib
            
            req = urllib.request.Request(
                ai_service_url,
                data=json_lib.dumps(ai_payload).encode("utf-8"),
                headers={"Content-Type": "application/json"},
                method="POST"
            )
            
            with urllib.request.urlopen(req, timeout=15) as resp:
                ai_result = json_lib.loads(resp.read().decode("utf-8"))
                
        except Exception as e:
            ai_result = {"error": str(e), "status": "AI service unavailable"}
        
        # üíæ SAVE TO ai_analysis TABLE
        record_id = None
        blockchain_tx = None
        try:
            if ai_result and isinstance(ai_result, dict):
                logger.info(f"üíæ Saving AI analysis to ai_analysis table...")
                
                with get_db_conn() as conn:
                    with conn.cursor() as cur:
                        insert_query = """
                        INSERT INTO ai_analysis (
                            sensor_reading_id,
                            analysis_type,
                            analysis_mode,
                            analyzed_at_vn,
                            crop_recommendation,
                            soil_health,
                            anomaly_detection,
                            model_version,
                            confidence_avg,
                            onchain_status
                        )
                        VALUES (%s, %s, %s, NOW(), %s, %s, %s, %s, %s, %s)
                        RETURNING id
                        """
                        
                        crop_rec = ai_result.get('crop_recommendation', {})
                        soil_health_data = ai_result.get('soil_health', {})
                        anomaly = ai_result.get('anomaly_detection', {})
                        
                        import json as json_module
                        
                        cur.execute(insert_query, (
                            sensor_reading_id,                          # sensor_reading_id (LINK TO LATEST SAMPLE)
                            'realtime',                                 # analysis_type (changed from 'daily')
                            'discovery',                                # analysis_mode
                            json_module.dumps(crop_rec),               # crop_recommendation
                            json_module.dumps(soil_health_data),       # soil_health
                            json_module.dumps(anomaly),                # anomaly_detection
                            'v1.0',                                    # model_version
                            crop_rec.get('confidence', 0),             # confidence_avg
                            'pending'                                   # onchain_status
                        ))
                        
                        result = cur.fetchone()
                        record_id = result[0] if result else None
                        conn.commit()
                        
                logger.info(f"‚úÖ Saved to ai_analysis (ID: {record_id})")
                
                # üîó PUSH TO BLOCKCHAIN
                try:
                    logger.info(f"‚õìÔ∏è  Pushing to blockchain...")
                    # TODO: Call blockchain service
                    blockchain_tx = "0x" + "0" * 64  # Placeholder
                    logger.info(f"‚úÖ Blockchain TX: {blockchain_tx}")
                except Exception as bc_error:
                    logger.error(f"‚ö†Ô∏è Blockchain push failed: {bc_error}")
                    blockchain_tx = None
                
        except Exception as save_error:
            logger.error(f"‚ö†Ô∏è Failed to save AI analysis: {save_error}", exc_info=True)
        
        return jsonify({
            "status": "success",
            "data_type": "latest_sample",
            "measured_at": latest_data['measured_at'],
            "sensor_reading_id": sensor_reading_id,
            "data": latest_data,
            "ai_analysis": ai_result,
            "saved_to_db": record_id is not None,
            "record_id": record_id,
            "blockchain_tx": blockchain_tx
        }), 200
        
    except Exception as e:
        logger.error(f"‚ùå Analyze-and-save error: {e}", exc_info=True)
        return jsonify({"status": "error", "message": str(e)}), 500


# ============================================================
# FASTAPI APP (AI Service)
# ============================================================

fastapi_app = FastAPI(
    title="Pione AI Service (Embedded)",
    description="AI Analysis Service for Soil Data",
    version="1.0.0"
)

fastapi_app.add_middleware(
    FastAPICORS,
    allow_origins=["*"],
    allow_credentials=True,
    allow_methods=["*"],
    allow_headers=["*"],
)

START_TIME = time.time()

@fastapi_app.get("/ai/", tags=["Root"])
async def ai_root():
    return {
        "service": "Pione AI Service (Embedded)",
        "version": "1.0.0",
        "status": "running"
    }


@fastapi_app.get("/ai/health", response_model=HealthCheckResponse, tags=["Health"])
async def ai_health_check():
    models = get_model_registry()
    
    if not models.validate_loaded():
        try:
            logger.info("üîÑ Lazy loading models on first health check...")
            models.load_all()
        except Exception as e:
            logger.error(f"‚ùå Failed to load models: {e}")
    
    uptime = time.time() - START_TIME
    
    return HealthCheckResponse(
        status="healthy" if models.validate_loaded() else "unhealthy",
        models_loaded=26 if models.validate_loaded() else 0,
        model_names=[
            "crop_classifier",
            "soil_health_scorer",
            "anomaly_detector",
            f"crop_validators ({len(models.crop_validators)})"
        ],
        uptime_seconds=round(uptime, 2)
    )


@fastapi_app.post("/analyze", response_model=AIAnalysisResponse, tags=["Analysis"])
async def analyze_soil_data(data: SoilDataInput):
    try:
        models = get_model_registry()
        
        if not models.validate_loaded():
            try:
                logger.info("üîÑ Lazy loading models (first request)...")
                models.load_all()
                logger.info("‚úÖ Models loaded successfully!")
            except Exception as e:
                logger.error(f"‚ùå Failed to load models: {e}")
                raise HTTPException(status_code=503, detail=f"Models not loaded: {str(e)}")
        
        if data.mode == "validation":
            if not data.selected_crop:
                raise HTTPException(status_code=400, detail="selected_crop is required for validation mode")
            
            available_crops = models.get_crop_names()
            if data.selected_crop not in available_crops:
                raise HTTPException(status_code=400, detail=f"Invalid crop '{data.selected_crop}'. Available: {available_crops}")
        
        logger.info(f"\nüì® Received analysis request (mode: {data.mode})")
        result = analyze_soil(data, models)
        
        return result
        
    except HTTPException:
        raise
    except Exception as e:
        logger.error(f"‚ùå Analysis error: {e}", exc_info=True)
        raise HTTPException(status_code=500, detail=str(e))


@fastapi_app.post("/analyze-daily", response_model=DailyAnalysisResponse, tags=["Daily Aggregation"])
async def analyze_daily(request: DailyAggregateInput):
    try:
        models = get_model_registry()
        
        if not models.validate_loaded():
            try:
                logger.info("üîÑ Lazy loading models (first request)...")
                models.load_all()
                logger.info("‚úÖ Models loaded successfully!")
            except Exception as e:
                logger.error(f"‚ùå Failed to load models: {e}")
                raise HTTPException(status_code=503, detail=f"Models not loaded: {str(e)}")
        
        logger.info(f"\nüìÖ Daily aggregation request for date: {request.date}")
        
        aggregated_data = aggregate_daily_data(request.date)
        
        if not aggregated_data:
            raise HTTPException(status_code=404, detail=f"No sensor data found for date {request.date}")
        
        logger.info(f"   ‚úÖ Aggregated {aggregated_data['sample_count']} samples")
        
        ai_result = analyze_aggregated_data(aggregated_data['features'], models)
        
        record_id = save_daily_insight(request.date, aggregated_data, ai_result)
        
        logger.info(f"   ‚úÖ Saved to daily_insights (ID: {record_id})")
        
        blockchain_success, tx_hash, blockchain_status = push_to_blockchain(
            daily_insight_id=record_id,
            date=request.date,
            ai_result=ai_result,
            sample_count=aggregated_data['sample_count']
        )
        
        if blockchain_success:
            logger.info(f"   ‚úÖ Pushed to blockchain successfully (TX: {tx_hash})")
        else:
            logger.warning(f"   ‚ö†Ô∏è Blockchain push failed (status: {blockchain_status})")
        
        return DailyAnalysisResponse(
            date=request.date,
            aggregated_data=aggregated_data,
            ai_analysis=ai_result,
            saved_to_db=True,
            record_id=record_id
        )
        
    except HTTPException:
        raise
    except Exception as e:
        logger.error(f"‚ùå Daily aggregation error: {e}", exc_info=True)
        raise HTTPException(status_code=500, detail=str(e))


# ============================================================
# USE FLASK AS MAIN APP (FastAPI mounting disabled - using Flask wrappers instead)
# ============================================================

from werkzeug.serving import run_simple

# Use Flask app directly - no FastAPI mounting
# All AI logic called via internal inference functions
application = flask_app


# ============================================================
# MAIN
# ============================================================

if __name__ == "__main__":
    PORT = int(os.getenv("BACKEND_PORT", "8080"))
    HOST = os.getenv("BACKEND_HOST", "0.0.0.0")
    
    logger.info('\n‚ïî‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïó')
    logger.info('‚ïë                                                            ‚ïë')
    logger.info('‚ïë        ü§ñ UNIFIED BACKEND - Flask + FastAPI ü§ñ             ‚ïë')
    logger.info('‚ïë                                                            ‚ïë')
    logger.info('‚ïö‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïù')
    logger.info(f'\n‚úÖ Backend running on: http://{HOST}:{PORT}')
    logger.info(f'\nüìç Endpoints:')
    logger.info(f'   üì• Data Ingest:       http://localhost:{PORT}/api/data')
    logger.info(f'   üìä Latest:            http://localhost:{PORT}/api/latest')
    logger.info(f'   üìú History:           http://localhost:{PORT}/api/history')
    logger.info(f'   üë§ Auth:              http://localhost:{PORT}/api/auth/*')
    logger.info(f'   üìà Dashboard:         http://localhost:{PORT}/api/dashboard/*')
    logger.info(f'   üí¨ AI Chat:           http://localhost:{PORT}/api/ai/chat')
    logger.info(f'   ü§ñ AI Analyze:        http://localhost:{PORT}/api/ai/analyze')
    logger.info(f'   üìÖ AI Daily:          http://localhost:{PORT}/api/ai/analyze-daily')
    logger.info(f'   ‚ù§Ô∏è  Health:            http://localhost:{PORT}/api/health')
    logger.info('\n')
    
    # Run with Werkzeug (development) or use Gunicorn (production)
    run_simple(HOST, PORT, application, use_reloader=False, use_debugger=False, threaded=True)

